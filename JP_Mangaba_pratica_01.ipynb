{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtKtaDlnPwx0j12VSBd0eR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaopaulonasc/CiscoPacketTracer/blob/main/JP_Mangaba_pratica_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE5LORdpfcEy",
        "outputId": "6d9f4baf-cdf4-46dc-8df2-0e9b8146200f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mangaba_ai'...\n",
            "remote: Enumerating objects: 448, done.\u001b[K\n",
            "remote: Counting objects: 100% (161/161), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 448 (delta 67), reused 119 (delta 52), pack-reused 287 (from 1)\u001b[K\n",
            "Receiving objects: 100% (448/448), 3.14 MiB | 8.75 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Mangaba-ai/mangaba_ai.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mangaba_ai\n",
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMzBqFFmghQZ",
        "outputId": "5b8a600e-0608-4c06-8784-f2a613d39c79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mangaba_ai\n",
            "Processing /content/mangaba_ai\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-generativeai>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from mangaba-ai==1.0.0) (0.8.5)\n",
            "Requirement already satisfied: python-dotenv>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mangaba-ai==1.0.0) (1.1.1)\n",
            "Collecting loguru>=0.6.0 (from mangaba-ai==1.0.0)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pydantic>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from mangaba-ai==1.0.0) (2.11.7)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.12/dist-packages (from mangaba-ai==1.0.0) (2.32.4)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.12/dist-packages (from mangaba-ai==1.0.0) (15.0.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.3.0->mangaba-ai==1.0.0) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.3.0->mangaba-ai==1.0.0) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.3.0->mangaba-ai==1.0.0) (2.179.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.3.0->mangaba-ai==1.0.0) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.3.0->mangaba-ai==1.0.0) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.3.0->mangaba-ai==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai>=0.3.0->mangaba-ai==1.0.0) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (1.26.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->mangaba-ai==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->mangaba-ai==1.0.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->mangaba-ai==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->mangaba-ai==1.0.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->mangaba-ai==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->mangaba-ai==1.0.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->mangaba-ai==1.0.0) (2025.8.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.3.0->mangaba-ai==1.0.0) (0.6.1)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mangaba-ai\n",
            "  Building wheel for mangaba-ai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mangaba-ai: filename=mangaba_ai-1.0.0-py3-none-any.whl size=28120 sha256=6e97d53784310e64e017f0f704b58581f9149c211d7577c15627d1196b5599c3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h0kouj8j/wheels/a5/a6/d9/d58997caf82077818d9e6eddd6ed270205698abebad944be1a\n",
            "Successfully built mangaba-ai\n",
            "Installing collected packages: loguru, mangaba-ai\n",
            "Successfully installed loguru-0.7.3 mangaba-ai-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "PVQF1U5qhPAN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mangaba_ai import MangabaAgent"
      ],
      "metadata": {
        "id": "-5Em0TH1hgiY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Cria√ß√£o de uma classe de assistente inteligente com hist√≥rico persistente\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class AssistenteInteligente:\n",
        "    def __init__(self, agent_id):\n",
        "        self.agente = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id)\n",
        "        self.historico = []\n",
        "\n",
        "    def interagir(self, mensagem):\n",
        "        self.historico.append(mensagem)\n",
        "        resposta = self.agente.chat(mensagem)\n",
        "        self.historico.append(resposta)\n",
        "        return resposta\n",
        "\n",
        "assistente = AssistenteInteligente(agent_id=\"assistente1\")\n",
        "print(assistente.interagir(\"Explique a iniciativa Mangaba AI de Sergipe\"))\n",
        "print(assistente.interagir(\"Fa√ßa um resumo em t√≥picos da explica√ß√£o anterior.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "-qntmFmthjZn",
        "outputId": "195a54c1-bc0e-4b41-9faf-5604127ddcd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m20:15:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[assistente1]\u001b[0m | \u001b[1m‚úÖ Agente inicializado - ID: assistente1, Modelo: gemini-2.5-flash\u001b[0m\n",
            "\u001b[32m20:15:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[assistente1]\u001b[0m | \u001b[1müí¨ Chat: Explique a iniciativa Mangaba AI de Sergipe... ‚Üí A iniciativa **Mangaba AI de Sergipe** √© um projet...\u001b[0m\n",
            "A iniciativa **Mangaba AI de Sergipe** √© um projeto ambicioso e pioneiro que busca posicionar o estado de Sergipe como um polo de inova√ß√£o e desenvolvimento em Intelig√™ncia Artificial (IA), com um forte foco na aplica√ß√£o dessa tecnologia para impulsionar a economia local, promover a sustentabilidade e qualificar a sua for√ßa de trabalho.\n",
            "\n",
            "O nome \"Mangaba AI\" √© simb√≥lico: a **mangaba** √© um fruto nativo e representativo do Nordeste brasileiro, incluindo Sergipe, remetendo √† identidade local e √† riqueza natural do estado. \"AI\" (Artificial Intelligence) aponta para a modernidade, a tecnologia de ponta e o futuro. Juntos, eles representam a uni√£o entre a voca√ß√£o natural e cultural de Sergipe e o potencial transformador da tecnologia.\n",
            "\n",
            "**Principais Pilares e Objetivos:**\n",
            "\n",
            "1.  **Desenvolvimento de Talentos em IA:**\n",
            "    *   Fomentar a forma√ß√£o e capacita√ß√£o de profissionais em IA, desde o ensino b√°sico at√© o superior e p√≥s-gradua√ß√£o.\n",
            "    *   Parcerias com universidades (como a UFS - Universidade Federal de Sergipe e a UNIT - Universidade Tiradentes) e institui√ß√µes de ensino t√©cnico para criar cursos, programas de resid√™ncia e trilhas de aprendizado em √°reas como ci√™ncia de dados, machine learning, vis√£o computacional, entre outras.\n",
            "\n",
            "2.  **IA para o Agroneg√≥cio (Agro 4.0):**\n",
            "    *   Uma das aplica√ß√µes mais importantes √© no setor agr√≠cola, otimizando a produ√ß√£o, monitorando culturas (inclusive a mangaba, de forma simb√≥lica e pr√°tica), prevendo pragas e doen√ßas, e gerenciando recursos h√≠dricos e solos de forma mais eficiente.\n",
            "    *   Uso de sensores, drones e an√°lise de dados para aumentar a produtividade e a sustentabilidade no campo sergipano.\n",
            "\n",
            "3.  **Fomento ao Ecossistema de Inova√ß√£o:**\n",
            "    *   Incentivar a cria√ß√£o e o desenvolvimento de startups de IA em Sergipe.\n",
            "    *   Promover a colabora√ß√£o entre a academia, o setor privado e o governo para gerar solu√ß√µes inovadoras e aplic√°veis √†s necessidades do estado.\n",
            "    *   Atra√ß√£o de investimentos e empresas de tecnologia para Sergipe.\n",
            "\n",
            "4.  **IA para a Gest√£o P√∫blica e Servi√ßos Inteligentes:**\n",
            "    *   Desenvolver solu√ß√µes de IA para melhorar a efici√™ncia da gest√£o p√∫blica, otimizar servi√ßos ao cidad√£o, planejar pol√≠ticas p√∫blicas baseadas em dados e impulsionar o conceito de \"cidades inteligentes\".\n",
            "\n",
            "5.  **Sustentabilidade e Monitoramento Ambiental:**\n",
            "    *   Aplicar IA para monitorar ecossistemas, prever desastres naturais, gerenciar res√≠duos e apoiar a conserva√ß√£o ambiental, alinhando o desenvolvimento tecnol√≥gico com a preserva√ß√£o dos recursos naturais de Sergipe.\n",
            "\n",
            "**Import√¢ncia e Impacto Esperado:**\n",
            "\n",
            "*   **Diversifica√ß√£o Econ√¥mica:** Reduzir a depend√™ncia de setores tradicionais e criar novas fontes de riqueza.\n",
            "*   **Gera√ß√£o de Empregos de Alto Valor:** Criar oportunidades para profissionais qualificados em tecnologia, atraindo e retendo talentos no estado.\n",
            "*   **Competitividade:** Posicionar Sergipe na vanguarda da tecnologia e inova√ß√£o no cen√°rio nacional e internacional.\n",
            "*   **Melhora na Qualidade de Vida:** Atrav√©s de servi√ßos p√∫blicos mais eficientes, um agroneg√≥cio mais sustent√°vel e um ambiente de neg√≥cios mais din√¢mico.\n",
            "\n",
            "Em resumo, a iniciativa Mangaba AI √© a aposta estrat√©gica de Sergipe na intelig√™ncia artificial como motor de transforma√ß√£o econ√¥mica, social e ambiental, utilizando sua identidade regional como inspira√ß√£o para construir um futuro mais tecnol√≥gico e pr√≥spero.\n",
            "\u001b[32m20:15:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[assistente1]\u001b[0m | \u001b[1müí¨ Chat: Fa√ßa um resumo em t√≥picos da explica√ß√£o anterior.... ‚Üí Com certeza! Aqui est√° um resumo em t√≥picos da ini...\u001b[0m\n",
            "Com certeza! Aqui est√° um resumo em t√≥picos da iniciativa Mangaba AI de Sergipe:\n",
            "\n",
            "*   **Vis√£o Geral:** Projeto pioneiro para posicionar Sergipe como polo de inova√ß√£o em Intelig√™ncia Artificial (IA), focando na economia local, sustentabilidade e qualifica√ß√£o da for√ßa de trabalho.\n",
            "*   **Nome Simb√≥lico:**\n",
            "    *   **Mangaba:** Fruto nativo de Sergipe, remetendo √† identidade local e riqueza natural.\n",
            "    *   **AI:** Representa modernidade, tecnologia de ponta e futuro.\n",
            "    *   Juntos, simbolizam a uni√£o da voca√ß√£o cultural com o potencial tecnol√≥gico.\n",
            "*   **Principais Pilares e Objetivos:**\n",
            "    1.  **Desenvolvimento de Talentos em IA:** Fomentar forma√ß√£o desde o ensino b√°sico ao superior, com parcerias (UFS, UNIT).\n",
            "    2.  **IA para o Agroneg√≥cio (Agro 4.0):** Otimizar produ√ß√£o, monitorar culturas, prever pragas, gerenciar recursos h√≠dricos e solos com sensores, drones e an√°lise de dados.\n",
            "    3.  **Fomento ao Ecossistema de Inova√ß√£o:** Incentivar startups de IA, promover colabora√ß√£o (academia, setor privado, governo) e atrair investimentos.\n",
            "    4.  **IA para a Gest√£o P√∫blica e Servi√ßos Inteligentes:** Melhorar efici√™ncia governamental, otimizar servi√ßos ao cidad√£o e impulsionar \"cidades inteligentes\".\n",
            "    5.  **Sustentabilidade e Monitoramento Ambiental:** Aplicar IA para monitorar ecossistemas, prever desastres, gerenciar res√≠duos e apoiar a conserva√ß√£o.\n",
            "*   **Import√¢ncia e Impacto Esperado:**\n",
            "    *   **Diversifica√ß√£o Econ√¥mica:** Novas fontes de riqueza, reduzindo depend√™ncia de setores tradicionais.\n",
            "    *   **Gera√ß√£o de Empregos de Alto Valor:** Oportunidades para profissionais qualificados, atraindo e retendo talentos.\n",
            "    *   **Competitividade:** Sergipe na vanguarda da tecnologia nacional e internacional.\n",
            "    *   **Melhora na Qualidade de Vida:** Servi√ßos p√∫blicos mais eficientes, agroneg√≥cio sustent√°vel e ambiente de neg√≥cios din√¢mico.\n",
            "*   **Em Resumo:** Aposta estrat√©gica de Sergipe na IA como motor de transforma√ß√£o econ√¥mica, social e ambiental, com inspira√ß√£o na identidade regional.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A iniciativa **Mangaba AI de Sergipe** √© um projeto ambicioso e pioneiro que busca posicionar o estado de Sergipe como um polo de inova√ß√£o e desenvolvimento em Intelig√™ncia Artificial (IA), com um forte foco na aplica√ß√£o dessa tecnologia para impulsionar a economia local, promover a sustentabilidade e qualificar a sua for√ßa de trabalho.\n",
        "\n",
        "O nome \"Mangaba AI\" √© simb√≥lico: a **mangaba** √© um fruto nativo e representativo do Nordeste brasileiro, incluindo Sergipe, remetendo √† identidade local e √† riqueza natural do estado. \"AI\" (Artificial Intelligence) aponta para a modernidade, a tecnologia de ponta e o futuro. Juntos, eles representam a uni√£o entre a voca√ß√£o natural e cultural de Sergipe e o potencial transformador da tecnologia.\n",
        "\n",
        "**Principais Pilares e Objetivos:**\n",
        "\n",
        "1.  **Desenvolvimento de Talentos em IA:**\n",
        "    *   Fomentar a forma√ß√£o e capacita√ß√£o de profissionais em IA, desde o ensino b√°sico at√© o superior e p√≥s-gradua√ß√£o.\n",
        "    *   Parcerias com universidades (como a UFS - Universidade Federal de Sergipe e a UNIT - Universidade Tiradentes) e institui√ß√µes de ensino t√©cnico para criar cursos, programas de resid√™ncia e trilhas de aprendizado em √°reas como ci√™ncia de dados, machine learning, vis√£o computacional, entre outras.\n",
        "\n",
        "2.  **IA para o Agroneg√≥cio (Agro 4.0):**\n",
        "    *   Uma das aplica√ß√µes mais importantes √© no setor agr√≠cola, otimizando a produ√ß√£o, monitorando culturas (inclusive a mangaba, de forma simb√≥lica e pr√°tica), prevendo pragas e doen√ßas, e gerenciando recursos h√≠dricos e solos de forma mais eficiente.\n",
        "    *   Uso de sensores, drones e an√°lise de dados para aumentar a produtividade e a sustentabilidade no campo sergipano.\n",
        "\n",
        "3.  **Fomento ao Ecossistema de Inova√ß√£o:**\n",
        "    *   Incentivar a cria√ß√£o e o desenvolvimento de startups de IA em Sergipe.\n",
        "    *   Promover a colabora√ß√£o entre a academia, o setor privado e o governo para gerar solu√ß√µes inovadoras e aplic√°veis √†s necessidades do estado.\n",
        "    *   Atra√ß√£o de investimentos e empresas de tecnologia para Sergipe.\n",
        "\n",
        "4.  **IA para a Gest√£o P√∫blica e Servi√ßos Inteligentes:**\n",
        "    *   Desenvolver solu√ß√µes de IA para melhorar a efici√™ncia da gest√£o p√∫blica, otimizar servi√ßos ao cidad√£o, planejar pol√≠ticas p√∫blicas baseadas em dados e impulsionar o conceito de \"cidades inteligentes\".\n",
        "\n",
        "5.  **Sustentabilidade e Monitoramento Ambiental:**\n",
        "    *   Aplicar IA para monitorar ecossistemas, prever desastres naturais, gerenciar res√≠duos e apoiar a conserva√ß√£o ambiental, alinhando o desenvolvimento tecnol√≥gico com a preserva√ß√£o dos recursos naturais de Sergipe.\n",
        "\n",
        "**Import√¢ncia e Impacto Esperado:**\n",
        "\n",
        "*   **Diversifica√ß√£o Econ√¥mica:** Reduzir a depend√™ncia de setores tradicionais e criar novas fontes de riqueza.\n",
        "*   **Gera√ß√£o de Empregos de Alto Valor:** Criar oportunidades para profissionais qualificados em tecnologia, atraindo e retendo talentos no estado.\n",
        "*   **Competitividade:** Posicionar Sergipe na vanguarda da tecnologia e inova√ß√£o no cen√°rio nacional e internacional.\n",
        "*   **Melhora na Qualidade de Vida:** Atrav√©s de servi√ßos p√∫blicos mais eficientes, um agroneg√≥cio mais sustent√°vel e um ambiente de neg√≥cios mais din√¢mico.\n",
        "\n",
        "---\n",
        "\n",
        "*   **Vis√£o Geral:** Projeto pioneiro para posicionar Sergipe como polo de inova√ß√£o em Intelig√™ncia Artificial (IA), focando na economia local, sustentabilidade e qualifica√ß√£o da for√ßa de trabalho.\n",
        "*   **Nome Simb√≥lico:**\n",
        "    *   **Mangaba:** Fruto nativo de Sergipe, remetendo √† identidade local e riqueza natural.\n",
        "    *   **AI:** Representa modernidade, tecnologia de ponta e futuro.\n",
        "    *   Juntos, simbolizam a uni√£o da voca√ß√£o cultural com o potencial tecnol√≥gico.\n",
        "*   **Principais Pilares e Objetivos:**\n",
        "    1.  **Desenvolvimento de Talentos em IA:** Fomentar forma√ß√£o desde o ensino b√°sico ao superior, com parcerias (UFS, UNIT).\n",
        "    2.  **IA para o Agroneg√≥cio (Agro 4.0):** Otimizar produ√ß√£o, monitorar culturas, prever pragas, gerenciar recursos h√≠dricos e solos com sensores, drones e an√°lise de dados.\n",
        "    3.  **Fomento ao Ecossistema de Inova√ß√£o:** Incentivar startups de IA, promover colabora√ß√£o (academia, setor privado, governo) e atrair investimentos.\n",
        "    4.  **IA para a Gest√£o P√∫blica e Servi√ßos Inteligentes:** Melhorar efici√™ncia governamental, otimizar servi√ßos ao cidad√£o e impulsionar \"cidades inteligentes\".\n",
        "    5.  **Sustentabilidade e Monitoramento Ambiental:** Aplicar IA para monitorar ecossistemas, prever desastres, gerenciar res√≠duos e apoiar a conserva√ß√£o.\n",
        "*   **Import√¢ncia e Impacto Esperado:**\n",
        "    *   **Diversifica√ß√£o Econ√¥mica:** Novas fontes de riqueza, reduzindo depend√™ncia de setores tradicionais.\n",
        "    *   **Gera√ß√£o de Empregos de Alto Valor:** Oportunidades para profissionais qualificados, atraindo e retendo talentos.\n",
        "    *   **Competitividade:** Sergipe na vanguarda da tecnologia nacional e internacional.\n",
        "    *   **Melhora na Qualidade de Vida:** Servi√ßos p√∫blicos mais eficientes, agroneg√≥cio sustent√°vel e ambiente de neg√≥cios din√¢mico.\n",
        "*   **Em Resumo:** Aposta estrat√©gica de Sergipe na IA como motor de transforma√ß√£o econ√¥mica, social e ambiental, com inspira√ß√£o na identidade regional."
      ],
      "metadata": {
        "id": "nf8nevBijxai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Classe para sumariza√ß√£o autom√°tica de textos longos usando MangabaAgent\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class ResumidorDeTextos:\n",
        "    def __init__(self, agent_id=\"resumidor\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id)\n",
        "\n",
        "    def resumir(self, texto, frases=3):\n",
        "        prompt = f\"Resuma o texto abaixo em {frases} frases:\\n{texto}\"\n",
        "        return self.agent.chat(prompt)\n",
        "\n",
        "texto_longo = \"\"\"Mangaba AI √© um framework brasileiro open source para automa√ß√£o inteligente usando equipes de agentes aut√¥nomos, desenvolvido em Python. Ele foi criado pelo Dr. Dheiver Santos, especialista em Intelig√™ncia Artificial, com o foco em permitir que agentes especializados colaborem para resolver tarefas complexas de forma coordenada, eficiente e inteligente.[1][5]\n",
        "\n",
        "Principais caracter√≠sticas do Mangaba AI:\n",
        "\n",
        "- **Arquitetura multi-agente**: Permite criar equipes de agentes inteligentes, cada um com fun√ß√µes espec√≠ficas (por exemplo, buscar informa√ß√µes, analisar dados, gerar relat√≥rios), que atuam de forma colaborativa.[5][1]\n",
        "- **Mem√≥ria contextual**: Os agentes compartilham hist√≥rico individual e coletivo para manter continuidade e melhorar os resultados.[1][5]\n",
        "- **Integra√ß√£o com modelos avan√ßados**: Suporta nativamente integra√ß√£o com modelos Gemini (IA da Google) para ampliar as capacidades cognitivas dos agentes.[5][1]\n",
        "- **Ferramentas externas**: Pode acessar APIs e realizar buscas em tempo real (como via Google Search) para expandir a automa√ß√£o e o acesso √† informa√ß√£o.[1][5]\n",
        "- **Gerenciamento inteligente de tarefas**: Organiza fluxos, depend√™ncias e prioridades automaticamente para garantir efici√™ncia.[5][1]\n",
        "- **Processamento ass√≠ncrono**: Permite a execu√ß√£o paralela das tarefas, acelerando a resolu√ß√£o de problemas complexos.[1]\n",
        "- **API intuitiva**: Projetado com uma API simples e f√°cil de aprender, oferecendo exemplos claros para quem est√° iniciando com agentes aut√¥nomos.[1]\n",
        "\n",
        "### Aplica√ß√µes pr√°ticas\n",
        "\n",
        "O Mangaba AI pode ser explorado em diversos setores, como:\n",
        "- An√°lise inteligente de documentos\n",
        "- Gera√ß√£o automatizada de relat√≥rios\n",
        "- Pesquisa e desenvolvimento avan√ßado\n",
        "- Automa√ß√£o de processos repetitivos\n",
        "- Cria√ß√£o de assistentes virtuais\n",
        "- An√°lise de sentimento em dados de clientes ou redes sociais\n",
        "- Automatiza√ß√£o de processos financeiros (ex: categoriza√ß√£o de gastos, previs√£o de fluxo de caixa, detec√ß√£o de anomalias financeiras)[7]\n",
        "\n",
        "### Curiosidade sobre o nome\n",
        "\n",
        "O nome e a identidade visual do Mangaba AI s√£o inspirados na fruta mangaba, nativa do Brasil, s√≠mbolo de versatilidade e capacidade de adapta√ß√£o‚Äîvalores que o framework busca refletir. As cores remetem ao ciclo natural da fruta, associando-se ao crescimento e evolu√ß√£o dos agentes de IA dentro do sistema.[5][1]\n",
        "\n",
        "### Aprendizado e comunidade\n",
        "\n",
        "O framework tem ganhado destaque na comunidade de IA pelo seu enfoque moderno e colaborativo, sendo tema de cursos pr√°ticos, palestras e discuss√µes entre profissionais do setor de tecnologia, inova√ß√£o e neg√≥cios.[2][9][5]\n",
        "\n",
        "Se voc√™ quer criar solu√ß√µes modulares e escal√°veis em IA, principalmente voltadas para automa√ß√£o corporativa, pesquisa ou workflows inteligentes, Mangaba AI √© uma √≥tima op√ß√£o para r√°pida prototipagem e projetos aut√¥nomos.[9][5][1]\n",
        "\"\"\"\n",
        "resumidor = ResumidorDeTextos()\n",
        "print(resumidor.resumir(texto_longo, frases=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "0OrcpBCwlU25",
        "outputId": "dcacfb82-9bdd-43e1-d9bf-56f43cc6167c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m20:21:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[resumidor]\u001b[0m | \u001b[1m‚úÖ Agente inicializado - ID: resumidor, Modelo: gemini-2.5-flash\u001b[0m\n",
            "\u001b[32m20:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[resumidor]\u001b[0m | \u001b[1müí¨ Chat: Resuma o texto abaixo em 2 frases:\n",
            "Mangaba AI √© um... ‚Üí Mangaba AI √© um framework brasileiro open source e...\u001b[0m\n",
            "Mangaba AI √© um framework brasileiro open source em Python, desenvolvido pelo Dr. Dheiver Santos, que utiliza equipes de agentes aut√¥nomos para automa√ß√£o inteligente e resolu√ß√£o coordenada de tarefas complexas. Ele oferece uma arquitetura multi-agente com mem√≥ria contextual e integra√ß√£o a modelos avan√ßados, ideal para otimizar processos em an√°lise de documentos, automa√ß√£o corporativa e pesquisa em diversos setores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mangaba AI √© um framework brasileiro open source em Python, desenvolvido pelo Dr. Dheiver Santos, que utiliza equipes de agentes aut√¥nomos para automa√ß√£o inteligente e resolu√ß√£o coordenada de tarefas complexas. Ele oferece uma arquitetura multi-agente com mem√≥ria contextual e integra√ß√£o a modelos avan√ßados, ideal para otimizar processos em an√°lise de documentos, automa√ß√£o corporativa e pesquisa em diversos setores."
      ],
      "metadata": {
        "id": "S4vPQpXLmIE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Classe que integra busca, an√°lise e gera√ß√£o de relat√≥rio estruturado\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class RelatorioIA:\n",
        "    def __init__(self, agent_id=\"relatorio\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id, tools=[\"search\"])\n",
        "\n",
        "    def gerar_relatorio(self, tema):\n",
        "        resultados = self.agent.run_tool(\"search\", parameters={\"query\": tema})\n",
        "        analise = self.agent.chat(f\"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{resultados}\")\n",
        "        return analise\n",
        "\n",
        "relatorio = RelatorioIA()\n",
        "print(relatorio.gerar_relatorio(\"Impacto da IA na agricultura brasileira\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "y_b-ZQRemQN-",
        "outputId": "8fc62591-bb36-4b7f-8640-cc44c28fd65f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MangabaAgent.__init__() got an unexpected keyword argument 'tools'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3269312917.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manalise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mrelatorio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRelatorioIA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelatorio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgerar_relatorio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Impacto da IA na agricultura brasileira\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3269312917.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, agent_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRelatorioIA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relatorio\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMangabaAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemini-2.5-flash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"search\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgerar_relatorio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MangabaAgent.__init__() got an unexpected keyword argument 'tools'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Classe para revis√£o e sugest√£o de melhorias em c√≥digos fornecidos\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class RevisorCodigo:\n",
        "    def __init__(self, agent_id=\"revisor\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id)\n",
        "\n",
        "    def revisar(self, codigo):\n",
        "        prompt = f\"Revise o c√≥digo abaixo e sugira melhorias seguindo boas pr√°ticas Python:\\n{codigo}\"\n",
        "        return self.agent.chat(prompt)\n",
        "\n",
        "codigo_exemplo = '''\n",
        "#Classe que integra busca, an√°lise e gera√ß√£o de relat√≥rio estruturado\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class RelatorioIA:\n",
        "    def __init__(self, agent_id=\"relatorio\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id, tools=[\"search\"])\n",
        "\n",
        "    def gerar_relatorio(self, tema):\n",
        "        resultados = self.agent.run_tool(\"search\", parameters={\"query\": tema})\n",
        "        analise = self.agent.chat(f\"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{resultados}\")\n",
        "        return analise\n",
        "\n",
        "relatorio = RelatorioIA()\n",
        "print(relatorio.gerar_relatorio(\"Impacto da IA na agricultura brasileira\"))\n",
        "'''\n",
        "revisor = RevisorCodigo()\n",
        "print(revisor.revisar(codigo_exemplo))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0sgILmdFrX9A",
        "outputId": "a2d5e674-b978-470e-ba12-b34813fb8b06"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m20:45:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[revisor]\u001b[0m | \u001b[1m‚úÖ Agente inicializado - ID: revisor, Modelo: gemini-2.5-flash\u001b[0m\n",
            "\u001b[32m20:46:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[revisor]\u001b[0m | \u001b[1müí¨ Chat: Revise o c√≥digo abaixo e sugira melhorias seguindo... ‚Üí O c√≥digo √© um bom ponto de partida para integrar u...\u001b[0m\n",
            "O c√≥digo √© um bom ponto de partida para integrar uma busca e gera√ß√£o de relat√≥rio com IA. No entanto, h√° v√°rias melhorias que podem ser aplicadas seguindo boas pr√°ticas Python, especialmente em termos de robustez, flexibilidade, legibilidade e manutenibilidade.\n",
            "\n",
            "Aqui est√£o as sugest√µes, categorizadas para facilitar a revis√£o:\n",
            "\n",
            "---\n",
            "\n",
            "### **Revis√£o e Sugest√µes de Melhoria**\n",
            "\n",
            "#### 1. **Docstrings e Type Hinting**\n",
            "\n",
            "*   **Problema:** O c√≥digo n√£o possui docstrings nem type hints.\n",
            "*   **Melhoria:** Adicionar docstrings para a classe e seus m√©todos, explicando o prop√≥sito, par√¢metros e retornos. Adicionar type hints para os argumentos dos m√©todos e retornos para melhorar a legibilidade e a detec√ß√£o de erros.\n",
            "\n",
            "```python\n",
            "# ...\n",
            "class RelatorioIA:\n",
            "    \"\"\"\n",
            "    Classe para integrar busca, an√°lise e gera√ß√£o de relat√≥rios estruturados\n",
            "    utilizando um agente de IA (MangabaAgent).\n",
            "    \"\"\"\n",
            "    def __init__(self, agent_id: str = \"relatorio\", model: str = \"gemini-2.5-flash\", tools: list[str] = None):\n",
            "        \"\"\"\n",
            "        Inicializa a classe RelatorioIA com um MangabaAgent configurado.\n",
            "\n",
            "        Args:\n",
            "            agent_id (str): ID √∫nico para o agente de IA.\n",
            "            model (str): Nome do modelo de IA a ser utilizado (e.g., \"gemini-2.5-flash\").\n",
            "            tools (list[str]): Lista de ferramentas a serem disponibilizadas para o agente.\n",
            "                                Padr√£o para [\"search\"] se n√£o for fornecido.\n",
            "        \"\"\"\n",
            "        if tools is None:\n",
            "            tools = [\"search\"]\n",
            "        self.agent = MangabaAgent(model=model, agent_id=agent_id, tools=tools)\n",
            "\n",
            "    def gerar_relatorio(self, tema: str) -> str:\n",
            "        \"\"\"\n",
            "        Gera um relat√≥rio estruturado sobre um tema espec√≠fico.\n",
            "\n",
            "        Realiza uma busca pelo tema, analisa os resultados e gera um relat√≥rio\n",
            "        cr√≠tico utilizando o agente de IA.\n",
            "\n",
            "        Args:\n",
            "            tema (str): O t√≥pico ou tema sobre o qual o relat√≥rio ser√° gerado.\n",
            "\n",
            "        Returns:\n",
            "            str: O relat√≥rio estruturado gerado pelo agente de IA.\n",
            "        \"\"\"\n",
            "        # ... (restante do m√©todo)\n",
            "```\n",
            "\n",
            "#### 2. **Flexibilidade e Configura√ß√£o**\n",
            "\n",
            "*   **Problema:** O modelo de IA (`\"gemini-2.5-flash\"`) e as ferramentas (`[\"search\"]`) est√£o \"hardcoded\" no `__init__`.\n",
            "*   **Melhoria:** Permitir que o modelo e as ferramentas sejam configur√°veis via par√¢metros do construtor, com valores padr√£o razo√°veis. Isso torna a classe mais reutiliz√°vel sem modifica√ß√µes diretas.\n",
            "\n",
            "```python\n",
            "# ... (ver exemplo acima no __init__)\n",
            "class RelatorioIA:\n",
            "    def __init__(self, agent_id: str = \"relatorio\", model: str = \"gemini-2.5-flash\", tools: list[str] = None):\n",
            "        if tools is None:\n",
            "            tools = [\"search\"] # Garantir que o valor padr√£o seja um objeto mut√°vel novo\n",
            "        self.agent = MangabaAgent(model=model, agent_id=agent_id, tools=tools)\n",
            "```\n",
            "\n",
            "#### 3. **Tratamento de Erros e Robustez**\n",
            "\n",
            "*   **Problema:** O c√≥digo n√£o lida com poss√≠veis falhas na chamada `run_tool` ou `chat` (ex: erros de rede, API, resultados vazios).\n",
            "*   **Melhoria:**\n",
            "    *   Usar blocos `try-except` para capturar exce√ß√µes das chamadas √† API.\n",
            "    *   Verificar se os `resultados` da busca n√£o est√£o vazios ou s√£o inv√°lidos antes de pass√°-los para a an√°lise.\n",
            "    *   Retornar uma mensagem de erro ou lan√ßar uma exce√ß√£o personalizada em caso de falha.\n",
            "    *   Implementar logging para depura√ß√£o e monitoramento.\n",
            "\n",
            "```python\n",
            "import logging\n",
            "# from mangaba_ai import MangabaAgent # Assumindo que MangabaAgent lan√ßa exce√ß√µes espec√≠ficas ou gen√©ricas\n",
            "\n",
            "# Configura√ß√£o b√°sica de logging\n",
            "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
            "\n",
            "class RelatorioIA:\n",
            "    # ... (init conforme revisado)\n",
            "\n",
            "    def gerar_relatorio(self, tema: str) -> str:\n",
            "        logging.info(f\"Iniciando gera√ß√£o de relat√≥rio para o tema: '{tema}'\")\n",
            "        resultados = None\n",
            "        try:\n",
            "            logging.info(f\"Executando busca por: '{tema}'\")\n",
            "            resultados = self.agent.run_tool(\"search\", parameters={\"query\": tema})\n",
            "            if not resultados:\n",
            "                logging.warning(f\"A busca por '{tema}' n√£o retornou resultados.\")\n",
            "                return \"N√£o foi poss√≠vel encontrar dados relevantes para gerar o relat√≥rio.\"\n",
            "            logging.info(f\"Resultados da busca obtidos. Tamanho: {len(str(resultados))} caracteres.\")\n",
            "        except Exception as e:\n",
            "            logging.error(f\"Erro ao executar a ferramenta 'search' para o tema '{tema}': {e}\")\n",
            "            return f\"Erro ao buscar dados: {e}\"\n",
            "\n",
            "        analise = None\n",
            "        try:\n",
            "            prompt = f\"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{resultados}\"\n",
            "            logging.info(\"Iniciando an√°lise e gera√ß√£o do relat√≥rio com o agente de IA.\")\n",
            "            # Considerar truncar 'resultados' se for muito longo para evitar limites de token\n",
            "            # ou dividir a tarefa para o agente.\n",
            "            analise = self.agent.chat(prompt)\n",
            "            if not analise:\n",
            "                logging.warning(\"O agente de IA n√£o conseguiu gerar uma an√°lise para os dados fornecidos.\")\n",
            "                return \"O agente de IA n√£o conseguiu gerar um relat√≥rio.\"\n",
            "            logging.info(\"Relat√≥rio gerado com sucesso.\")\n",
            "            return analise\n",
            "        except Exception as e:\n",
            "            logging.error(f\"Erro ao gerar a an√°lise/relat√≥rio pelo agente de IA para o tema '{tema}': {e}\")\n",
            "            return f\"Erro ao analisar dados e gerar relat√≥rio: {e}\"\n",
            "\n",
            "```\n",
            "\n",
            "#### 4. **Logging**\n",
            "\n",
            "*   **Problema:** O c√≥digo n√£o possui nenhum mecanismo de logging.\n",
            "*   **Melhoria:** Integrar a biblioteca `logging` do Python para registrar o fluxo de execu√ß√£o, avisos e erros. Isso √© fundamental para depura√ß√£o e monitoramento em produ√ß√£o. (J√° inclu√≠do no exemplo de Tratamento de Erros).\n",
            "\n",
            "#### 5. **Separa√ß√£o de Preocupa√ß√µes e Reusabilidade (Prompt Engineering)**\n",
            "\n",
            "*   **Problema:** O prompt para o agente est√° \"hardcoded\" dentro do m√©todo `gerar_relatorio`.\n",
            "*   **Melhoria:**\n",
            "    *   Definir o prompt como uma constante da classe ou um par√¢metro, permitindo ajustes sem modificar a l√≥gica do m√©todo.\n",
            "    *   Considerar que prompts podem se tornar complexos. Uma abordagem mais estruturada (e.g., templates de prompt, separa√ß√£o de instru√ß√µes e dados) pode ser √∫til.\n",
            "    *   Adicionar par√¢metros ao `chat` como `temperature`, `top_p`, etc., se o `MangabaAgent` os suportar, para controlar a criatividade e a diversidade das respostas.\n",
            "\n",
            "```python\n",
            "# ...\n",
            "class RelatorioIA:\n",
            "    DEFAULT_REPORT_PROMPT = \"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{data}\"\n",
            "    # ... (init)\n",
            "\n",
            "    def gerar_relatorio(self, tema: str, prompt_template: str = None, **chat_kwargs) -> str:\n",
            "        # ... (c√≥digo existente)\n",
            "\n",
            "        if prompt_template is None:\n",
            "            prompt_template = self.DEFAULT_REPORT_PROMPT\n",
            "\n",
            "        # Adicione l√≥gica para lidar com a substitui√ß√£o de {data} ou outro placeholder\n",
            "        # Aqui, {data} ser√° substitu√≠do por resultados\n",
            "        final_prompt = prompt_template.format(data=resultados)\n",
            "\n",
            "        try:\n",
            "            logging.info(\"Iniciando an√°lise e gera√ß√£o do relat√≥rio com o agente de IA.\")\n",
            "            # **chat_kwargs permitiria passar temperatura, top_p, etc., se suportado pelo MangabaAgent.chat()\n",
            "            analise = self.agent.chat(final_prompt, **chat_kwargs)\n",
            "            # ... (restante do c√≥digo)\n",
            "```\n",
            "\n",
            "#### 6. **Gerenciamento de Tamanho de Entrada (Token Limits)**\n",
            "\n",
            "*   **Problema:** Os resultados da busca (`resultados`) podem ser muito longos, excedendo os limites de token do modelo de IA e/ou aumentando os custos.\n",
            "*   **Melhoria:** Implementar uma estrat√©gia para gerenciar o tamanho dos `resultados` antes de pass√°-los para o `chat` do agente. Isso pode envolver:\n",
            "    *   **Truncagem:** Simplesmente cortar o texto ap√≥s um certo n√∫mero de caracteres/tokens.\n",
            "    *   **Resumo Pr√©vio:** Usar o pr√≥prio agente (ou um agente menor/mais barato) para resumir os resultados da busca *antes* de envi√°-los para a gera√ß√£o do relat√≥rio final.\n",
            "    *   **Processamento em Batches:** Dividir os resultados em partes e process√°-las individualmente.\n",
            "\n",
            "```python\n",
            "# ... (dentro de gerar_relatorio, ap√≥s obter resultados)\n",
            "MAX_RESULT_LENGTH = 8000  # Exemplo: Limite de caracteres para evitar estouro de tokens\n",
            "if len(str(resultados)) > MAX_RESULT_LENGTH:\n",
            "    logging.warning(f\"Resultados da busca excedem {MAX_RESULT_LENGTH} caracteres. Truncando.\")\n",
            "    # Uma forma simples de truncar (pode ser melhorado para truncar em limites de frase, etc.)\n",
            "    resultados_truncados = str(resultados)[:MAX_RESULT_LENGTH] + \" [TRUNCADO...]\"\n",
            "else:\n",
            "    resultados_truncados = resultados\n",
            "\n",
            "prompt = f\"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{resultados_truncados}\"\n",
            "# ... (restante do m√©todo)\n",
            "```\n",
            "\n",
            "#### 7. **Considera√ß√µes Adicionais (Async/Wait)**\n",
            "\n",
            "*   **Problema:** Se as chamadas √† API `run_tool` e `chat` forem I/O-bound (o que √© muito prov√°vel), o c√≥digo atual √© s√≠ncrono e bloquear√° a execu√ß√£o.\n",
            "*   **Melhoria (futura):** Se `MangabaAgent` suportar chamadas ass√≠ncronas (e.g., `async_run_tool`, `async_chat`), considere refatorar a classe para usar `asyncio` e `await` para melhor desempenho em aplica√ß√µes que precisam de concorr√™ncia.\n",
            "\n",
            "```python\n",
            "# Exemplo hipot√©tico com async/await (requer MangabaAgent ass√≠ncrono)\n",
            "# class RelatorioIA:\n",
            "#     # ...\n",
            "#     async def gerar_relatorio_async(self, tema: str) -> str:\n",
            "#         try:\n",
            "#             resultados = await self.agent.async_run_tool(\"search\", parameters={\"query\": tema})\n",
            "#             if not resultados:\n",
            "#                 return \"N√£o foi poss√≠vel encontrar dados relevantes.\"\n",
            "#         except Exception as e:\n",
            "#             return f\"Erro ao buscar dados: {e}\"\n",
            "#\n",
            "#         try:\n",
            "#             analise = await self.agent.async_chat(f\"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{resultados}\")\n",
            "#             return analise\n",
            "#         except Exception as e:\n",
            "#             return f\"Erro ao analisar dados e gerar relat√≥rio: {e}\"\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### **C√≥digo Final Sugerido (com as melhorias principais)**\n",
            "\n",
            "```python\n",
            "import logging\n",
            "from mangaba_ai import MangabaAgent # Assumindo que esta biblioteca est√° instalada e funcional\n",
            "\n",
            "# Configura√ß√£o b√°sica de logging\n",
            "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
            "\n",
            "class RelatorioIA:\n",
            "    \"\"\"\n",
            "    Classe para integrar busca, an√°lise e gera√ß√£o de relat√≥rios estruturados\n",
            "    utilizando um agente de IA (MangabaAgent).\n",
            "    \"\"\"\n",
            "    DEFAULT_REPORT_PROMPT_TEMPLATE = (\n",
            "        \"Com base nos dados fornecidos, analise criticamente as informa√ß√µes e gere um relat√≥rio estruturado.\\n\"\n",
            "        \"O relat√≥rio deve ser objetivo, cobrir os pontos principais e apresentar uma conclus√£o.\\n\"\n",
            "        \"Dados para an√°lise:\\n{data}\"\n",
            "    )\n",
            "    MAX_SEARCH_RESULTS_TOKENS = 4000 # Exemplo: Limite de tokens para resultados de busca antes de enviar ao LLM\n",
            "\n",
            "    def __init__(self, agent_id: str = \"relatorio\", model: str = \"gemini-2.5-flash\", tools: list[str] = None):\n",
            "        \"\"\"\n",
            "        Inicializa a classe RelatorioIA com um MangabaAgent configurado.\n",
            "\n",
            "        Args:\n",
            "            agent_id (str): ID √∫nico para o agente de IA.\n",
            "            model (str): Nome do modelo de IA a ser utilizado (e.g., \"gemini-2.5-flash\").\n",
            "            tools (list[str]): Lista de ferramentas a serem disponibilizadas para o agente.\n",
            "                                Padr√£o para [\"search\"] se n√£o for fornecido.\n",
            "        \"\"\"\n",
            "        if tools is None:\n",
            "            tools = [\"search\"] # Garantir que o valor padr√£o seja um objeto mut√°vel novo\n",
            "        self.agent = MangabaAgent(model=model, agent_id=agent_id, tools=tools)\n",
            "        logging.info(f\"RelatorioIA inicializado com agent_id='{agent_id}', model='{model}', tools={tools}\")\n",
            "\n",
            "    def gerar_relatorio(self, tema: str, prompt_template: str = None, **chat_kwargs) -> str:\n",
            "        \"\"\"\n",
            "        Gera um relat√≥rio estruturado sobre um tema espec√≠fico.\n",
            "\n",
            "        Realiza uma busca pelo tema, analisa os resultados e gera um relat√≥rio\n",
            "        cr√≠tico utilizando o agente de IA.\n",
            "\n",
            "        Args:\n",
            "            tema (str): O t√≥pico ou tema sobre o qual o relat√≥rio ser√° gerado.\n",
            "            prompt_template (str, opcional): Template de string para o prompt do agente.\n",
            "                                             Deve conter '{data}' para a inser√ß√£o dos resultados.\n",
            "                                             Usa DEFAULT_REPORT_PROMPT_TEMPLATE se None.\n",
            "            **chat_kwargs: Argumentos adicionais a serem passados para o m√©todo `self.agent.chat()`,\n",
            "                           como `temperature`, `top_p`, etc., se suportados pelo MangabaAgent.\n",
            "\n",
            "        Returns:\n",
            "            str: O relat√≥rio estruturado gerado pelo agente de IA, ou uma mensagem de erro.\n",
            "        \"\"\"\n",
            "        logging.info(f\"Iniciando gera√ß√£o de relat√≥rio para o tema: '{tema}'\")\n",
            "        raw_resultados = None\n",
            "\n",
            "        # 1. Executar a busca\n",
            "        try:\n",
            "            logging.debug(f\"Executando busca por: '{tema}' com a ferramenta 'search'.\")\n",
            "            raw_resultados = self.agent.run_tool(\"search\", parameters={\"query\": tema})\n",
            "\n",
            "            if not raw_resultados:\n",
            "                logging.warning(f\"A busca por '{tema}' n√£o retornou resultados. N√£o √© poss√≠vel gerar o relat√≥rio.\")\n",
            "                return \"N√£o foi poss√≠vel encontrar dados relevantes para gerar o relat√≥rio.\"\n",
            "\n",
            "            logging.info(f\"Resultados da busca obtidos. Tamanho: {len(str(raw_resultados))} caracteres.\")\n",
            "\n",
            "        except Exception as e:\n",
            "            logging.error(f\"Erro ao executar a ferramenta 'search' para o tema '{tema}': {e}\", exc_info=True)\n",
            "            return f\"Erro ao buscar dados: {e}\"\n",
            "\n",
            "        # 2. Pr√©-processar resultados (gerenciar limites de tokens)\n",
            "        processed_resultados = str(raw_resultados)\n",
            "        # Assumindo uma fun√ß√£o auxiliar para estimar tokens ou truncar\n",
            "        # Em um cen√°rio real, voc√™ usaria um tokenizer espec√≠fico do modelo\n",
            "        if len(processed_resultados.split()) > self.MAX_SEARCH_RESULTS_TOKENS:\n",
            "            logging.warning(f\"Resultados da busca excedem {self.MAX_SEARCH_RESULTS_TOKENS} tokens (aproximadamente). Truncando.\")\n",
            "            # Truncagem simples por palavras, pode ser refinado\n",
            "            processed_resultados = \" \".join(processed_resultados.split()[:self.MAX_SEARCH_RESULTS_TOKENS]) + \"\\n[...Dados truncados para caber no limite do modelo...]\"\n",
            "            logging.debug(f\"Resultados truncados. Novo tamanho: {len(processed_resultados)} caracteres.\")\n",
            "\n",
            "        # 3. Gerar o relat√≥rio com o agente de IA\n",
            "        analise = None\n",
            "        try:\n",
            "            current_prompt_template = prompt_template if prompt_template is not None else self.DEFAULT_REPORT_PROMPT_TEMPLATE\n",
            "            final_prompt = current_prompt_template.format(data=processed_resultados)\n",
            "\n",
            "            logging.debug(\"Iniciando an√°lise e gera√ß√£o do relat√≥rio com o agente de IA.\")\n",
            "            analise = self.agent.chat(final_prompt, **chat_kwargs)\n",
            "\n",
            "            if not analise:\n",
            "                logging.warning(\"O agente de IA n√£o conseguiu gerar uma an√°lise/relat√≥rio significativo para os dados fornecidos.\")\n",
            "                return \"O agente de IA n√£o conseguiu gerar um relat√≥rio com os dados dispon√≠veis.\"\n",
            "\n",
            "            logging.info(\"Relat√≥rio gerado com sucesso.\")\n",
            "            return analise\n",
            "\n",
            "        except Exception as e:\n",
            "            logging.error(f\"Erro ao gerar a an√°lise/relat√≥rio pelo agente de IA para o tema '{tema}': {e}\", exc_info=True)\n",
            "            return f\"Erro ao analisar dados e gerar relat√≥rio: {e}\"\n",
            "\n",
            "# --- Exemplo de Uso ---\n",
            "if __name__ == \"__main__\":\n",
            "    # Instanciando a classe com configura√ß√µes padr√£o\n",
            "    relatorio_generator = RelatorioIA()\n",
            "\n",
            "    # Gerando um relat√≥rio sobre um tema\n",
            "    tema_exemplo = \"Impacto da IA na agricultura brasileira\"\n",
            "    relatorio_gerado = relatorio_generator.gerar_relatorio(tema_exemplo)\n",
            "    print(\"\\n--- Relat√≥rio Gerado ---\")\n",
            "    print(relatorio_gerado)\n",
            "\n",
            "    # Exemplo com um prompt personalizado e par√¢metros de chat (se MangabaAgent suportar)\n",
            "    # relatorio_personalizado_generator = RelatorioIA(agent_id=\"relatorio_detalhado\")\n",
            "    # custom_prompt = \"Produza um relat√≥rio acad√™mico detalhado sobre {data}, focado em inova√ß√µes e desafios.\"\n",
            "    # relatorio_detalhado = relatorio_personalizado_generator.gerar_relatorio(\n",
            "    #     \"Desafios da sustentabilidade na cadeia de suprimentos\",\n",
            "    #     prompt_template=custom_prompt,\n",
            "    #     temperature=0.7, # Exemplo de par√¢metro para o chat do agente\n",
            "    #     top_p=0.9\n",
            "    # )\n",
            "    # print(\"\\n--- Relat√≥rio Detalhado Personalizado ---\")\n",
            "    # print(relatorio_detalhado)\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O c√≥digo √© um bom ponto de partida para integrar uma busca e gera√ß√£o de relat√≥rio com IA. No entanto, h√° v√°rias melhorias que podem ser aplicadas seguindo boas pr√°ticas Python, especialmente em termos de robustez, flexibilidade, legibilidade e manutenibilidade.\n",
        "\n",
        "Aqui est√£o as sugest√µes, categorizadas para facilitar a revis√£o:\n",
        "\n",
        "---\n",
        "\n",
        "### **Revis√£o e Sugest√µes de Melhoria**\n",
        "\n",
        "#### 1. **Docstrings e Type Hinting**\n",
        "\n",
        "*   **Problema:** O c√≥digo n√£o possui docstrings nem type hints.\n",
        "*   **Melhoria:** Adicionar docstrings para a classe e seus m√©todos, explicando o prop√≥sito, par√¢metros e retornos. Adicionar type hints para os argumentos dos m√©todos e retornos para melhorar a legibilidade e a detec√ß√£o de erros.\n",
        "\n",
        "```python\n",
        "# ...\n",
        "class RelatorioIA:\n",
        "    \"\"\"\n",
        "    Classe para integrar busca, an√°lise e gera√ß√£o de relat√≥rios estruturados\n",
        "    utilizando um agente de IA (MangabaAgent).\n",
        "    \"\"\"\n",
        "    def __init__(self, agent_id: str = \"relatorio\", model: str = \"gemini-2.5-flash\", tools: list[str] = None):\n",
        "        \"\"\"\n",
        "        Inicializa a classe RelatorioIA com um MangabaAgent configurado.\n",
        "\n",
        "        Args:\n",
        "            agent_id (str): ID √∫nico para o agente de IA.\n",
        "            model (str): Nome do modelo de IA a ser utilizado (e.g., \"gemini-2.5-flash\").\n",
        "            tools (list[str]): Lista de ferramentas a serem disponibilizadas para o agente.\n",
        "                                Padr√£o para [\"search\"] se n√£o for fornecido.\n",
        "        \"\"\"\n",
        "        if tools is None:\n",
        "            tools = [\"search\"]\n",
        "        self.agent = MangabaAgent(model=model, agent_id=agent_id, tools=tools)\n",
        "\n",
        "    def gerar_relatorio(self, tema: str) -> str:\n",
        "        \"\"\"\n",
        "        Gera um relat√≥rio estruturado sobre um tema espec√≠fico.\n",
        "\n",
        "        Realiza uma busca pelo tema, analisa os resultados e gera um relat√≥rio\n",
        "        cr√≠tico utilizando o agente de IA.\n",
        "\n",
        "        Args:\n",
        "            tema (str): O t√≥pico ou tema sobre o qual o relat√≥rio ser√° gerado.\n",
        "\n",
        "        Returns:\n",
        "            str: O relat√≥rio estruturado gerado pelo agente de IA.\n",
        "        \"\"\"\n",
        "        # ... (restante do m√©todo)\n",
        "```\n",
        "\n",
        "#### 2. **Flexibilidade e Configura√ß√£o**\n",
        "\n",
        "*   **Problema:** O modelo de IA (`\"gemini-2.5-flash\"`) e as ferramentas (`[\"search\"]`) est√£o \"hardcoded\" no `__init__`.\n",
        "*   **Melhoria:** Permitir que o modelo e as ferramentas sejam configur√°veis via par√¢metros do construtor, com valores padr√£o razo√°veis. Isso torna a classe mais reutiliz√°vel sem modifica√ß√µes diretas.\n",
        "\n",
        "```python\n",
        "# ... (ver exemplo acima no __init__)\n",
        "class RelatorioIA:\n",
        "    def __init__(self, agent_id: str = \"relatorio\", model: str = \"gemini-2.5-flash\", tools: list[str] = None):\n",
        "        if tools is None:\n",
        "            tools = [\"search\"] # Garantir que o valor padr√£o seja um objeto mut√°vel novo\n",
        "        self.agent = MangabaAgent(model=model, agent_id=agent_id, tools=tools)\n",
        "```\n",
        "\n",
        "#### 3. **Tratamento de Erros e Robustez**\n",
        "\n",
        "*   **Problema:** O c√≥digo n√£o lida com poss√≠veis falhas na chamada `run_tool` ou `chat` (ex: erros de rede, API, resultados vazios).\n",
        "*   **Melhoria:**\n",
        "    *   Usar blocos `try-except` para capturar exce√ß√µes das chamadas √† API.\n",
        "    *   Verificar se os `resultados` da busca n√£o est√£o vazios ou s√£o inv√°lidos antes de pass√°-los para a an√°lise.\n",
        "    *   Retornar uma mensagem de erro ou lan√ßar uma exce√ß√£o personalizada em caso de falha.\n",
        "    *   Implementar logging para depura√ß√£o e monitoramento.\n",
        "\n",
        "```python\n",
        "import logging\n",
        "# from mangaba_ai import MangabaAgent # Assumindo que MangabaAgent lan√ßa exce√ß√µes espec√≠ficas ou gen√©ricas\n",
        "\n",
        "# Configura√ß√£o b√°sica de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class RelatorioIA:\n",
        "    # ... (init conforme revisado)\n",
        "\n",
        "    def gerar_relatorio(self, tema: str) -> str:\n",
        "        logging.info(f\"Iniciando gera√ß√£o de relat√≥rio para o tema: '{tema}'\")\n",
        "        resultados = None\n",
        "        try:\n",
        "            logging.info(f\"Executando busca por: '{tema}'\")\n",
        "            resultados = self.agent.run_tool(\"search\", parameters={\"query\": tema})\n",
        "            if not resultados:\n",
        "                logging.warning(f\"A busca por '{tema}' n√£o retornou resultados.\")\n",
        "                return \"N√£o foi poss√≠vel encontrar dados relevantes para gerar o relat√≥rio.\"\n",
        "            logging.info(f\"Resultados da busca obtidos. Tamanho: {len(str(resultados))} caracteres.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro ao executar a ferramenta 'search' para o tema '{tema}': {e}\")\n",
        "            return f\"Erro ao buscar dados: {e}\"\n",
        "\n",
        "        analise = None\n",
        "        try:\n",
        "            prompt = f\"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{resultados}\"\n",
        "            logging.info(\"Iniciando an√°lise e gera√ß√£o do relat√≥rio com o agente de IA.\")\n",
        "            # Considerar truncar 'resultados' se for muito longo para evitar limites de token\n",
        "            # ou dividir a tarefa para o agente.\n",
        "            analise = self.agent.chat(prompt)\n",
        "            if not analise:\n",
        "                logging.warning(\"O agente de IA n√£o conseguiu gerar uma an√°lise para os dados fornecidos.\")\n",
        "                return \"O agente de IA n√£o conseguiu gerar um relat√≥rio.\"\n",
        "            logging.info(\"Relat√≥rio gerado com sucesso.\")\n",
        "            return analise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro ao gerar a an√°lise/relat√≥rio pelo agente de IA para o tema '{tema}': {e}\")\n",
        "            return f\"Erro ao analisar dados e gerar relat√≥rio: {e}\"\n",
        "\n",
        "```\n",
        "\n",
        "#### 4. **Logging**\n",
        "\n",
        "*   **Problema:** O c√≥digo n√£o possui nenhum mecanismo de logging.\n",
        "*   **Melhoria:** Integrar a biblioteca `logging` do Python para registrar o fluxo de execu√ß√£o, avisos e erros. Isso √© fundamental para depura√ß√£o e monitoramento em produ√ß√£o. (J√° inclu√≠do no exemplo de Tratamento de Erros).\n",
        "\n",
        "#### 5. **Separa√ß√£o de Preocupa√ß√µes e Reusabilidade (Prompt Engineering)**\n",
        "\n",
        "*   **Problema:** O prompt para o agente est√° \"hardcoded\" dentro do m√©todo `gerar_relatorio`.\n",
        "*   **Melhoria:**\n",
        "    *   Definir o prompt como uma constante da classe ou um par√¢metro, permitindo ajustes sem modificar a l√≥gica do m√©todo.\n",
        "    *   Considerar que prompts podem se tornar complexos. Uma abordagem mais estruturada (e.g., templates de prompt, separa√ß√£o de instru√ß√µes e dados) pode ser √∫til.\n",
        "    *   Adicionar par√¢metros ao `chat` como `temperature`, `top_p`, etc., se o `MangabaAgent` os suportar, para controlar a criatividade e a diversidade das respostas.\n",
        "\n",
        "```python\n",
        "# ...\n",
        "class RelatorioIA:\n",
        "    DEFAULT_REPORT_PROMPT = \"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{data}\"\n",
        "    # ... (init)\n",
        "\n",
        "    def gerar_relatorio(self, tema: str, prompt_template: str = None, **chat_kwargs) -> str:\n",
        "        # ... (c√≥digo existente)\n",
        "\n",
        "        if prompt_template is None:\n",
        "            prompt_template = self.DEFAULT_REPORT_PROMPT\n",
        "\n",
        "        # Adicione l√≥gica para lidar com a substitui√ß√£o de {data} ou outro placeholder\n",
        "        # Aqui, {data} ser√° substitu√≠do por resultados\n",
        "        final_prompt = prompt_template.format(data=resultados)\n",
        "\n",
        "        try:\n",
        "            logging.info(\"Iniciando an√°lise e gera√ß√£o do relat√≥rio com o agente de IA.\")\n",
        "            # **chat_kwargs permitiria passar temperatura, top_p, etc., se suportado pelo MangabaAgent.chat()\n",
        "            analise = self.agent.chat(final_prompt, **chat_kwargs)\n",
        "            # ... (restante do c√≥digo)\n",
        "```\n",
        "\n",
        "#### 6. **Gerenciamento de Tamanho de Entrada (Token Limits)**\n",
        "\n",
        "*   **Problema:** Os resultados da busca (`resultados`) podem ser muito longos, excedendo os limites de token do modelo de IA e/ou aumentando os custos.\n",
        "*   **Melhoria:** Implementar uma estrat√©gia para gerenciar o tamanho dos `resultados` antes de pass√°-los para o `chat` do agente. Isso pode envolver:\n",
        "    *   **Truncagem:** Simplesmente cortar o texto ap√≥s um certo n√∫mero de caracteres/tokens.\n",
        "    *   **Resumo Pr√©vio:** Usar o pr√≥prio agente (ou um agente menor/mais barato) para resumir os resultados da busca *antes* de envi√°-los para a gera√ß√£o do relat√≥rio final.\n",
        "    *   **Processamento em Batches:** Dividir os resultados em partes e process√°-las individualmente.\n",
        "\n",
        "```python\n",
        "# ... (dentro de gerar_relatorio, ap√≥s obter resultados)\n",
        "MAX_RESULT_LENGTH = 8000  # Exemplo: Limite de caracteres para evitar estouro de tokens\n",
        "if len(str(resultados)) > MAX_RESULT_LENGTH:\n",
        "    logging.warning(f\"Resultados da busca excedem {MAX_RESULT_LENGTH} caracteres. Truncando.\")\n",
        "    # Uma forma simples de truncar (pode ser melhorado para truncar em limites de frase, etc.)\n",
        "    resultados_truncados = str(resultados)[:MAX_RESULT_LENGTH] + \" [TRUNCADO...]\"\n",
        "else:\n",
        "    resultados_truncados = resultados\n",
        "\n",
        "prompt = f\"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{resultados_truncados}\"\n",
        "# ... (restante do m√©todo)\n",
        "```\n",
        "\n",
        "#### 7. **Considera√ß√µes Adicionais (Async/Wait)**\n",
        "\n",
        "*   **Problema:** Se as chamadas √† API `run_tool` e `chat` forem I/O-bound (o que √© muito prov√°vel), o c√≥digo atual √© s√≠ncrono e bloquear√° a execu√ß√£o.\n",
        "*   **Melhoria (futura):** Se `MangabaAgent` suportar chamadas ass√≠ncronas (e.g., `async_run_tool`, `async_chat`), considere refatorar a classe para usar `asyncio` e `await` para melhor desempenho em aplica√ß√µes que precisam de concorr√™ncia.\n",
        "\n",
        "```python\n",
        "# Exemplo hipot√©tico com async/await (requer MangabaAgent ass√≠ncrono)\n",
        "# class RelatorioIA:\n",
        "#     # ...\n",
        "#     async def gerar_relatorio_async(self, tema: str) -> str:\n",
        "#         try:\n",
        "#             resultados = await self.agent.async_run_tool(\"search\", parameters={\"query\": tema})\n",
        "#             if not resultados:\n",
        "#                 return \"N√£o foi poss√≠vel encontrar dados relevantes.\"\n",
        "#         except Exception as e:\n",
        "#             return f\"Erro ao buscar dados: {e}\"\n",
        "#\n",
        "#         try:\n",
        "#             analise = await self.agent.async_chat(f\"Analise criticamente os dados abaixo e gere um relat√≥rio estruturado:\\n{resultados}\")\n",
        "#             return analise\n",
        "#         except Exception as e:\n",
        "#             return f\"Erro ao analisar dados e gerar relat√≥rio: {e}\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **C√≥digo Final Sugerido (com as melhorias principais)**\n",
        "\n",
        "```python\n",
        "import logging\n",
        "from mangaba_ai import MangabaAgent # Assumindo que esta biblioteca est√° instalada e funcional\n",
        "\n",
        "# Configura√ß√£o b√°sica de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class RelatorioIA:\n",
        "    \"\"\"\n",
        "    Classe para integrar busca, an√°lise e gera√ß√£o de relat√≥rios estruturados\n",
        "    utilizando um agente de IA (MangabaAgent).\n",
        "    \"\"\"\n",
        "    DEFAULT_REPORT_PROMPT_TEMPLATE = (\n",
        "        \"Com base nos dados fornecidos, analise criticamente as informa√ß√µes e gere um relat√≥rio estruturado.\\n\"\n",
        "        \"O relat√≥rio deve ser objetivo, cobrir os pontos principais e apresentar uma conclus√£o.\\n\"\n",
        "        \"Dados para an√°lise:\\n{data}\"\n",
        "    )\n",
        "    MAX_SEARCH_RESULTS_TOKENS = 4000 # Exemplo: Limite de tokens para resultados de busca antes de enviar ao LLM\n",
        "\n",
        "    def __init__(self, agent_id: str = \"relatorio\", model: str = \"gemini-2.5-flash\", tools: list[str] = None):\n",
        "        \"\"\"\n",
        "        Inicializa a classe RelatorioIA com um MangabaAgent configurado.\n",
        "\n",
        "        Args:\n",
        "            agent_id (str): ID √∫nico para o agente de IA.\n",
        "            model (str): Nome do modelo de IA a ser utilizado (e.g., \"gemini-2.5-flash\").\n",
        "            tools (list[str]): Lista de ferramentas a serem disponibilizadas para o agente.\n",
        "                                Padr√£o para [\"search\"] se n√£o for fornecido.\n",
        "        \"\"\"\n",
        "        if tools is None:\n",
        "            tools = [\"search\"] # Garantir que o valor padr√£o seja um objeto mut√°vel novo\n",
        "        self.agent = MangabaAgent(model=model, agent_id=agent_id, tools=tools)\n",
        "        logging.info(f\"RelatorioIA inicializado com agent_id='{agent_id}', model='{model}', tools={tools}\")\n",
        "\n",
        "    def gerar_relatorio(self, tema: str, prompt_template: str = None, **chat_kwargs) -> str:\n",
        "        \"\"\"\n",
        "        Gera um relat√≥rio estruturado sobre um tema espec√≠fico.\n",
        "\n",
        "        Realiza uma busca pelo tema, analisa os resultados e gera um relat√≥rio\n",
        "        cr√≠tico utilizando o agente de IA.\n",
        "\n",
        "        Args:\n",
        "            tema (str): O t√≥pico ou tema sobre o qual o relat√≥rio ser√° gerado.\n",
        "            prompt_template (str, opcional): Template de string para o prompt do agente.\n",
        "                                             Deve conter '{data}' para a inser√ß√£o dos resultados.\n",
        "                                             Usa DEFAULT_REPORT_PROMPT_TEMPLATE se None.\n",
        "            **chat_kwargs: Argumentos adicionais a serem passados para o m√©todo `self.agent.chat()`,\n",
        "                           como `temperature`, `top_p`, etc., se suportados pelo MangabaAgent.\n",
        "\n",
        "        Returns:\n",
        "            str: O relat√≥rio estruturado gerado pelo agente de IA, ou uma mensagem de erro.\n",
        "        \"\"\"\n",
        "        logging.info(f\"Iniciando gera√ß√£o de relat√≥rio para o tema: '{tema}'\")\n",
        "        raw_resultados = None\n",
        "\n",
        "        # 1. Executar a busca\n",
        "        try:\n",
        "            logging.debug(f\"Executando busca por: '{tema}' com a ferramenta 'search'.\")\n",
        "            raw_resultados = self.agent.run_tool(\"search\", parameters={\"query\": tema})\n",
        "\n",
        "            if not raw_resultados:\n",
        "                logging.warning(f\"A busca por '{tema}' n√£o retornou resultados. N√£o √© poss√≠vel gerar o relat√≥rio.\")\n",
        "                return \"N√£o foi poss√≠vel encontrar dados relevantes para gerar o relat√≥rio.\"\n",
        "\n",
        "            logging.info(f\"Resultados da busca obtidos. Tamanho: {len(str(raw_resultados))} caracteres.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro ao executar a ferramenta 'search' para o tema '{tema}': {e}\", exc_info=True)\n",
        "            return f\"Erro ao buscar dados: {e}\"\n",
        "\n",
        "        # 2. Pr√©-processar resultados (gerenciar limites de tokens)\n",
        "        processed_resultados = str(raw_resultados)\n",
        "        # Assumindo uma fun√ß√£o auxiliar para estimar tokens ou truncar\n",
        "        # Em um cen√°rio real, voc√™ usaria um tokenizer espec√≠fico do modelo\n",
        "        if len(processed_resultados.split()) > self.MAX_SEARCH_RESULTS_TOKENS:\n",
        "            logging.warning(f\"Resultados da busca excedem {self.MAX_SEARCH_RESULTS_TOKENS} tokens (aproximadamente). Truncando.\")\n",
        "            # Truncagem simples por palavras, pode ser refinado\n",
        "            processed_resultados = \" \".join(processed_resultados.split()[:self.MAX_SEARCH_RESULTS_TOKENS]) + \"\\n[...Dados truncados para caber no limite do modelo...]\"\n",
        "            logging.debug(f\"Resultados truncados. Novo tamanho: {len(processed_resultados)} caracteres.\")\n",
        "\n",
        "        # 3. Gerar o relat√≥rio com o agente de IA\n",
        "        analise = None\n",
        "        try:\n",
        "            current_prompt_template = prompt_template if prompt_template is not None else self.DEFAULT_REPORT_PROMPT_TEMPLATE\n",
        "            final_prompt = current_prompt_template.format(data=processed_resultados)\n",
        "\n",
        "            logging.debug(\"Iniciando an√°lise e gera√ß√£o do relat√≥rio com o agente de IA.\")\n",
        "            analise = self.agent.chat(final_prompt, **chat_kwargs)\n",
        "\n",
        "            if not analise:\n",
        "                logging.warning(\"O agente de IA n√£o conseguiu gerar uma an√°lise/relat√≥rio significativo para os dados fornecidos.\")\n",
        "                return \"O agente de IA n√£o conseguiu gerar um relat√≥rio com os dados dispon√≠veis.\"\n",
        "\n",
        "            logging.info(\"Relat√≥rio gerado com sucesso.\")\n",
        "            return analise\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Erro ao gerar a an√°lise/relat√≥rio pelo agente de IA para o tema '{tema}': {e}\", exc_info=True)\n",
        "            return f\"Erro ao analisar dados e gerar relat√≥rio: {e}\"\n",
        "\n",
        "# --- Exemplo de Uso ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Instanciando a classe com configura√ß√µes padr√£o\n",
        "    relatorio_generator = RelatorioIA()\n",
        "\n",
        "    # Gerando um relat√≥rio sobre um tema\n",
        "    tema_exemplo = \"Impacto da IA na agricultura brasileira\"\n",
        "    relatorio_gerado = relatorio_generator.gerar_relatorio(tema_exemplo)\n",
        "    print(\"\\n--- Relat√≥rio Gerado ---\")\n",
        "    print(relatorio_gerado)\n",
        "\n",
        "    # Exemplo com um prompt personalizado e par√¢metros de chat (se MangabaAgent suportar)\n",
        "    # relatorio_personalizado_generator = RelatorioIA(agent_id=\"relatorio_detalhado\")\n",
        "    # custom_prompt = \"Produza um relat√≥rio acad√™mico detalhado sobre {data}, focado em inova√ß√µes e desafios.\"\n",
        "    # relatorio_detalhado = relatorio_personalizado_generator.gerar_relatorio(\n",
        "    #     \"Desafios da sustentabilidade na cadeia de suprimentos\",\n",
        "    #     prompt_template=custom_prompt,\n",
        "    #     temperature=0.7, # Exemplo de par√¢metro para o chat do agente\n",
        "    #     top_p=0.9\n",
        "    # )\n",
        "    # print(\"\\n--- Relat√≥rio Detalhado Personalizado ---\")\n",
        "    # print(relatorio_detalhado)\n",
        "```"
      ],
      "metadata": {
        "id": "VTxSAHhBrxIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Classe que interage com m√∫ltiplas ferramentas e combina resultados\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class MultiFerramentas:\n",
        "    def __init__(self, agent_id=\"multitools\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id, tools=[\"calculator\", \"search\"])\n",
        "\n",
        "    def pesquisa_com_calculo(self, assunto, expressao):\n",
        "        resultado_pesquisa = self.agent.run_tool(\"search\", parameters={\"query\": assunto})\n",
        "        resultado_calculo = self.agent.run_tool(\"calculator\", parameters={\"expression\": expressao})\n",
        "        analise = self.agent.chat(\n",
        "            f\"Com base na pesquisa:\\n{resultado_pesquisa}\\nE no resultado do c√°lculo ({expressao} = {resultado_calculo}), gere uma conclus√£o pr√°tica.\"\n",
        "        )\n",
        "        return analise\n",
        "\n",
        "multi = MultiFerramentas()\n",
        "print(multi.pesquisa_com_calculo(\"produ√ß√£o de energia solar no Brasil\", \"365*5.5\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "aXPOp6BXuGGW",
        "outputId": "e87bebef-c7a3-46a8-d022-086d20626f34"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "MangabaAgent.__init__() got an unexpected keyword argument 'tools'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1650022045.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manalise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmulti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiFerramentas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpesquisa_com_calculo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"produ√ß√£o de energia solar no Brasil\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"365*5.5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1650022045.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, agent_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMultiFerramentas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multitools\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMangabaAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemini-2.5-flash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"calculator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"search\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpesquisa_com_calculo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massunto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpressao\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MangabaAgent.__init__() got an unexpected keyword argument 'tools'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Classe que realiza entrevista t√©cnica simulada com base em tema\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class EntrevistadorIA:\n",
        "    def __init__(self, agent_id=\"entrevistador\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id)\n",
        "\n",
        "    def simular_entrevista(self, tema, respostas_usuario):\n",
        "        perguntas = self.agent.chat(f\"Crie 3 perguntas t√©cnicas sobre: {tema}\")\n",
        "        respostas = []\n",
        "        for pergunta, resposta_usuario in zip(perguntas.split('\\n'), respostas_usuario):\n",
        "            resposta_ia = self.agent.chat(f\"{pergunta}\\nResposta do candidato: {resposta_usuario}\\nAvalie a resposta e d√™ feedback.\")\n",
        "            respostas.append(resposta_ia)\n",
        "        return '\\n'.join(respostas)\n",
        "\n",
        "entrevistador = EntrevistadorIA()\n",
        "respostas_usuario = [\n",
        "    \"Um banco NoSQL armazena dados sem esquema fixo.\",\n",
        "    \"√â indicado para grandes volumes de dados n√£o estruturados.\",\n",
        "    \"Exemplo: MongoDB.\"\n",
        "]\n",
        "print(entrevistador.simular_entrevista(\"Banco de Dados NoSQL\", respostas_usuario))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a5pV1JgKur40",
        "outputId": "5aab4c53-4eb5-4417-a416-99920d0aeb06"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m21:00:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[entrevistador]\u001b[0m | \u001b[1m‚úÖ Agente inicializado - ID: entrevistador, Modelo: gemini-2.5-flash\u001b[0m\n",
            "\u001b[32m21:00:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[entrevistador]\u001b[0m | \u001b[1müí¨ Chat: Crie 3 perguntas t√©cnicas sobre: Banco de Dados No... ‚Üí Com certeza! Aqui est√£o 3 perguntas t√©cnicas sobre...\u001b[0m\n",
            "\u001b[32m21:00:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[entrevistador]\u001b[0m | \u001b[1müí¨ Chat: Com certeza! Aqui est√£o 3 perguntas t√©cnicas sobre... ‚Üí A afirma√ß√£o do candidato (\"Um banco NoSQL armazena...\u001b[0m\n",
            "\u001b[32m21:00:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[entrevistador]\u001b[0m | \u001b[1müí¨ Chat: \n",
            "Resposta do candidato: √â indicado para grandes vo... ‚Üí A afirma√ß√£o do candidato (\"√â indicado para grandes...\u001b[0m\n",
            "\u001b[32m21:01:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[entrevistador]\u001b[0m | \u001b[1müí¨ Chat: 1.  **Diferen√ßas Fundamentais e Tipos:** Quais s√£o... ‚Üí A resposta do candidato: \"Exemplo: MongoDB.\"\n",
            "\n",
            "---\n",
            "...\u001b[0m\n",
            "A afirma√ß√£o do candidato (\"Um banco NoSQL armazena dados sem esquema fixo.\") est√° **correta**, mas a avalia√ß√£o da sua adequa√ß√£o depende do contexto da pergunta que ele deveria estar respondendo.\n",
            "\n",
            "**Feedback:**\n",
            "\n",
            "1.  **Correc√ß√£o da Afirma√ß√£o:** A afirma√ß√£o em si est√° **correta**. Uma das caracter√≠sticas mais distintivas dos bancos de dados NoSQL √©, de facto, a sua capacidade de armazenar dados sem um esquema fixo ou r√≠gido, o que oferece grande flexibilidade.\n",
            "\n",
            "2.  **Contexto da Pergunta:** A sua instru√ß√£o original para o candidato (impl√≠cita pelo seu prompt anterior) era para \"Crie 3 perguntas t√©cnicas sobre: Banco de Dados NoSQL\". No entanto, o candidato forneceu uma *afirma√ß√£o* sobre NoSQL, e n√£o as 3 perguntas solicitadas.\n",
            "\n",
            "    *   Se a inten√ß√£o era que o candidato *respondesse* a uma das tr√™s perguntas que voc√™ gerou (que foram: 1. Diferen√ßas Fundamentais e Tipos; 2. Consist√™ncia e Escalabilidade - Teorema CAP; 3. Modelagem de Dados e Consultas), ent√£o esta resposta √© **extremamente insuficiente**. Embora a flexibilidade de esquema seja um ponto que poderia ser abordado na Pergunta 1 ou 3, a resposta do candidato n√£o aborda a profundidade ou os m√∫ltiplos aspectos que as suas perguntas exigiam.\n",
            "\n",
            "3.  **Profundidade da Resposta:** A resposta √© **muito superficial** para uma pergunta t√©cnica. Em um contexto de entrevista ou avalia√ß√£o t√©cnica, espera-se que um candidato v√° al√©m de uma defini√ß√£o b√°sica.\n",
            "\n",
            "**Em resumo:**\n",
            "\n",
            "*   **A afirma√ß√£o \"Um banco NoSQL armazena dados sem esquema fixo\" √© tecnicamente correta.**\n",
            "*   **Como resposta √†s suas 3 perguntas t√©cnicas geradas, √© completamente inadequada e superficial.** N√£o aborda a complexidade, as nuances, os exemplos ou os trade-offs esperados em uma discuss√£o t√©cnica aprofundada sobre NoSQL.\n",
            "\n",
            "**Sugest√£o de Feedback para o Candidato:**\n",
            "\n",
            "\"Sua afirma√ß√£o de que 'Um banco NoSQL armazena dados sem esquema fixo' est√° **correta** e capta uma das caracter√≠sticas mais importantes e distintivas dos bancos de dados NoSQL em compara√ß√£o com os relacionais.\n",
            "\n",
            "No entanto, para o n√≠vel de profundidade esperado em uma pergunta t√©cnica (e especialmente se a inten√ß√£o era responder a uma das tr√™s perguntas que foram propostas, como as sobre categorias, Teorema CAP ou modelagem de dados), essa resposta √© **muito gen√©rica e superficial**.\n",
            "\n",
            "Em um contexto t√©cnico, esperamos que voc√™ **elabore** sobre o que significa n√£o ter um esquema fixo, quais s√£o as **vantagens e desvantagens** dessa abordagem, para quais **cen√°rios** ela √© mais adequada e como isso **impacta** a forma como os dados s√£o modelados e consultados. Idealmente, a resposta deveria ter abordado de forma mais completa e detalhada os pontos espec√≠ficos levantados nas perguntas formuladas.\"\n",
            "A afirma√ß√£o do candidato (\"√â indicado para grandes volumes de dados n√£o estruturados.\") est√° **correta**, mas novamente, a avalia√ß√£o da sua adequa√ß√£o depende do contexto da pergunta que ele deveria estar respondendo e do n√≠vel de profundidade esperado.\n",
            "\n",
            "**Feedback:**\n",
            "\n",
            "1.  **Correc√ß√£o da Afirma√ß√£o:** A afirma√ß√£o em si est√° **correta**. Uma das principais raz√µes para a ado√ß√£o de bancos de dados NoSQL √©, de facto, a sua capacidade de gerenciar e armazenar grandes volumes de dados n√£o estruturados ou semi-estruturados de forma eficiente, algo que bancos de dados relacionais tradicionais n√£o fazem t√£o bem.\n",
            "\n",
            "2.  **Contexto da Pergunta:** As suas instru√ß√µes originais para o candidato eram para \"Crie 3 perguntas t√©cnicas sobre: Banco de Dados NoSQL\". As perguntas geradas foram:\n",
            "    *   1. Diferen√ßas Fundamentais e Tipos\n",
            "    *   2. Consist√™ncia e Escalabilidade - Teorema CAP\n",
            "    *   3. Modelagem de Dados e Consultas\n",
            "\n",
            "    A resposta do candidato √© uma caracter√≠stica geral dos bancos NoSQL, que poderia ser mencionada como um **cen√°rio de uso** na Pergunta 1 ou como uma **consequ√™ncia da flexibilidade de esquema** na Pergunta 3. No entanto, como resposta *independente* ou como tentativa de responder *qualquer uma* das suas perguntas com profundidade, ela √© **extremamente insuficiente e gen√©rica**. N√£o aborda os m√∫ltiplos aspectos, a complexidade ou as compara√ß√µes que as suas perguntas exigiam.\n",
            "\n",
            "3.  **Profundidade da Resposta:** A resposta √© **muito superficial** para uma pergunta t√©cnica. Em um contexto de entrevista ou avalia√ß√£o t√©cnica, espera-se que um candidato v√° al√©m de uma defini√ß√£o b√°sica e explique o *porqu√™*, o *como*, as *implica√ß√µes* e os *exemplos*.\n",
            "\n",
            "**Em resumo:**\n",
            "\n",
            "*   **A afirma√ß√£o \"√â indicado para grandes volumes de dados n√£o estruturados\" √© tecnicamente correta.**\n",
            "*   **Como resposta √†s suas 3 perguntas t√©cnicas geradas, √© completamente inadequada e superficial.** Ela n√£o demonstra a compreens√£o t√©cnica aprofundada esperada.\n",
            "\n",
            "**Sugest√£o de Feedback para o Candidato:**\n",
            "\n",
            "\"Sua afirma√ß√£o de que um banco NoSQL '√© indicado para grandes volumes de dados n√£o estruturados' est√° **correta** e capta uma das motiva√ß√µes chave para a sua ado√ß√£o. Essa √©, de facto, uma caracter√≠stica distintiva e um cen√°rio de uso fundamental para muitas solu√ß√µes NoSQL.\\n\\nNo entanto, para o n√≠vel de profundidade esperado em uma pergunta t√©cnica (e especialmente se a inten√ß√£o era responder a uma das tr√™s perguntas propostas, como as sobre categorias, Teorema CAP ou modelagem de dados), essa resposta √© **muito gen√©rica e superficial**.\\n\\nEm um contexto t√©cnico, esperamos que voc√™ **elabore** sobre o que isso significa na pr√°tica. Por exemplo, voc√™ poderia explicar:\n",
            "*   **Por que** os bancos NoSQL s√£o mais adequados para dados n√£o estruturados do que os bancos relacionais? (Mencionar flexibilidade de esquema, escalabilidade horizontal, etc.)\n",
            "*   Quais s√£o as **vantagens e desafios** de lidar com grandes volumes de dados n√£o estruturados em um NoSQL?\n",
            "*   Poderia dar **exemplos** de tipos de dados n√£o estruturados (logs, dados de sensores, posts de redes sociais) e como diferentes tipos de NoSQL (documento, chave-valor, colunar) podem ser usados para eles.\n",
            "*   Como isso **impacta** a forma como os dados s√£o armazenados, indexados e consultados em compara√ß√£o com um ambiente relacional.\n",
            "\n",
            "Aprofundar nesses pontos demonstraria uma compreens√£o t√©cnica muito mais completa.\"\n",
            "A resposta do candidato: \"Exemplo: MongoDB.\"\n",
            "\n",
            "---\n",
            "\n",
            "**Avalia√ß√£o da Resposta:**\n",
            "\n",
            "1.  **Correc√ß√£o da Afirma√ß√£o:** A men√ß√£o a \"MongoDB\" est√° **correta** como um exemplo de um banco de dados NoSQL. Especificamente, o MongoDB √© um banco de dados NoSQL do tipo **orientado a documentos**.\n",
            "\n",
            "2.  **Contexto da Pergunta:** A pergunta era complexa e multifacetada, exigindo:\n",
            "    *   A identifica√ß√£o das **principais categorias** de bancos de dados NoSQL (Chave-Valor, Documento, Colunar, Grafo).\n",
            "    *   Os **cen√°rios de uso t√≠picos** para **cada uma** dessas categorias.\n",
            "    *   Uma **compara√ß√£o** da adequa√ß√£o dessas categorias em rela√ß√£o aos **bancos de dados relacionais tradicionais**.\n",
            "\n",
            "    A resposta do candidato, \"Exemplo: MongoDB\", aborda apenas uma pequena parte de uma das categorias (o tipo \"Documento\" tem MongoDB como um exemplo), mas n√£o descreve a categoria, seus cen√°rios de uso ou compara√ß√µes. Portanto, como resposta √† pergunta formulada, √© **completamente insuficiente e n√£o demonstra a compreens√£o esperada** dos m√∫ltiplos aspectos solicitados.\n",
            "\n",
            "3.  **Profundidade da Resposta:** A resposta √© **extremamente superficial**. Em um contexto t√©cnico, espera-se que um candidato v√° muito al√©m de apenas citar um exemplo, elaborando sobre os conceitos, aplica√ß√µes, vantagens e desvantagens de cada tipo de NoSQL.\n",
            "\n",
            "**Em resumo:**\n",
            "\n",
            "*   A men√ß√£o a \"MongoDB\" √© um exemplo v√°lido de um banco NoSQL (especificamente, orientado a documentos).\n",
            "*   Por√©m, como resposta √† pergunta 1, que exige uma descri√ß√£o das categorias, seus cen√°rios de uso e compara√ß√£o com bancos relacionais, √© **totalmente inadequada e n√£o demonstra o conhecimento t√©cnico aprofundado esperado**.\n",
            "\n",
            "---\n",
            "\n",
            "**Sugest√£o de Feedback para o Candidato:**\n",
            "\n",
            "\"Sua men√ß√£o a 'MongoDB' est√° **correta** como um exemplo de banco de dados NoSQL. De facto, ele √© um dos bancos de dados NoSQL mais populares e se encaixa na categoria de **bancos de dados orientados a documentos**.\"\n",
            "\n",
            "\"No entanto, a pergunta pedia uma discuss√£o **muito mais abrangente** sobre as diferentes categorias de bancos de dados NoSQL. Esperava-se que voc√™ identificasse e descrevesse as **principais categorias** (como Chave-Valor, Documento, Colunar e Grafo), e para **cada categoria**, discutisse seus **cen√°rios de uso t√≠picos** e, crucialmente, fizesse uma **compara√ß√£o** sobre quando cada uma delas √© mais adequada *em rela√ß√£o aos bancos de dados relacionais tradicionais*.\"\n",
            "\n",
            "\"Para o n√≠vel de profundidade esperado em uma pergunta t√©cnica, seria importante **elaborar** sobre cada tipo. Por exemplo, ao mencionar o MongoDB (Documento), voc√™ poderia ter explicado que ele √© ideal para dados semi-estruturados, documentos flex√≠veis como JSON, cat√°logos de produtos, perfis de usu√°rio, etc., destacando a flexibilidade de esquema como uma vantagem em compara√ß√£o com a rigidez de um esquema relacional.\"\n",
            "\n",
            "\"Uma resposta completa demonstraria sua capacidade de diferenciar as tecnologias NoSQL, entender seus pontos fortes e fracos, e aplic√°-los a problemas do mundo real, o que √© essencial para um n√≠vel t√©cnico.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "...\n",
        "A afirma√ß√£o do candidato (\"Um banco NoSQL armazena dados sem esquema fixo.\") est√° **correta**, mas a avalia√ß√£o da sua adequa√ß√£o depende do contexto da pergunta que ele deveria estar respondendo.\n",
        "\n",
        "**Feedback:**\n",
        "\n",
        "1.  **Correc√ß√£o da Afirma√ß√£o:** A afirma√ß√£o em si est√° **correta**. Uma das caracter√≠sticas mais distintivas dos bancos de dados NoSQL √©, de facto, a sua capacidade de armazenar dados sem um esquema fixo ou r√≠gido, o que oferece grande flexibilidade.\n",
        "\n",
        "2.  **Contexto da Pergunta:** A sua instru√ß√£o original para o candidato (impl√≠cita pelo seu prompt anterior) era para \"Crie 3 perguntas t√©cnicas sobre: Banco de Dados NoSQL\". No entanto, o candidato forneceu uma *afirma√ß√£o* sobre NoSQL, e n√£o as 3 perguntas solicitadas.\n",
        "\n",
        "    *   Se a inten√ß√£o era que o candidato *respondesse* a uma das tr√™s perguntas que voc√™ gerou (que foram: 1. Diferen√ßas Fundamentais e Tipos; 2. Consist√™ncia e Escalabilidade - Teorema CAP; 3. Modelagem de Dados e Consultas), ent√£o esta resposta √© **extremamente insuficiente**. Embora a flexibilidade de esquema seja um ponto que poderia ser abordado na Pergunta 1 ou 3, a resposta do candidato n√£o aborda a profundidade ou os m√∫ltiplos aspectos que as suas perguntas exigiam.\n",
        "\n",
        "3.  **Profundidade da Resposta:** A resposta √© **muito superficial** para uma pergunta t√©cnica. Em um contexto de entrevista ou avalia√ß√£o t√©cnica, espera-se que um candidato v√° al√©m de uma defini√ß√£o b√°sica.\n",
        "\n",
        "**Em resumo:**\n",
        "\n",
        "*   **A afirma√ß√£o \"Um banco NoSQL armazena dados sem esquema fixo\" √© tecnicamente correta.**\n",
        "*   **Como resposta √†s suas 3 perguntas t√©cnicas geradas, √© completamente inadequada e superficial.** N√£o aborda a complexidade, as nuances, os exemplos ou os trade-offs esperados em uma discuss√£o t√©cnica aprofundada sobre NoSQL.\n",
        "\n",
        "**Sugest√£o de Feedback para o Candidato:**\n",
        "\n",
        "\"Sua afirma√ß√£o de que 'Um banco NoSQL armazena dados sem esquema fixo' est√° **correta** e capta uma das caracter√≠sticas mais importantes e distintivas dos bancos de dados NoSQL em compara√ß√£o com os relacionais.\n",
        "\n",
        "No entanto, para o n√≠vel de profundidade esperado em uma pergunta t√©cnica (e especialmente se a inten√ß√£o era responder a uma das tr√™s perguntas que foram propostas, como as sobre categorias, Teorema CAP ou modelagem de dados), essa resposta √© **muito gen√©rica e superficial**.\n",
        "\n",
        "Em um contexto t√©cnico, esperamos que voc√™ **elabore** sobre o que significa n√£o ter um esquema fixo, quais s√£o as **vantagens e desvantagens** dessa abordagem, para quais **cen√°rios** ela √© mais adequada e como isso **impacta** a forma como os dados s√£o modelados e consultados. Idealmente, a resposta deveria ter abordado de forma mais completa e detalhada os pontos espec√≠ficos levantados nas perguntas formuladas.\"\n",
        "A afirma√ß√£o do candidato (\"√â indicado para grandes volumes de dados n√£o estruturados.\") est√° **correta**, mas novamente, a avalia√ß√£o da sua adequa√ß√£o depende do contexto da pergunta que ele deveria estar respondendo e do n√≠vel de profundidade esperado.\n",
        "\n",
        "**Feedback:**\n",
        "\n",
        "1.  **Correc√ß√£o da Afirma√ß√£o:** A afirma√ß√£o em si est√° **correta**. Uma das principais raz√µes para a ado√ß√£o de bancos de dados NoSQL √©, de facto, a sua capacidade de gerenciar e armazenar grandes volumes de dados n√£o estruturados ou semi-estruturados de forma eficiente, algo que bancos de dados relacionais tradicionais n√£o fazem t√£o bem.\n",
        "\n",
        "2.  **Contexto da Pergunta:** As suas instru√ß√µes originais para o candidato eram para \"Crie 3 perguntas t√©cnicas sobre: Banco de Dados NoSQL\". As perguntas geradas foram:\n",
        "    *   1. Diferen√ßas Fundamentais e Tipos\n",
        "    *   2. Consist√™ncia e Escalabilidade - Teorema CAP\n",
        "    *   3. Modelagem de Dados e Consultas\n",
        "\n",
        "    A resposta do candidato √© uma caracter√≠stica geral dos bancos NoSQL, que poderia ser mencionada como um **cen√°rio de uso** na Pergunta 1 ou como uma **consequ√™ncia da flexibilidade de esquema** na Pergunta 3. No entanto, como resposta *independente* ou como tentativa de responder *qualquer uma* das suas perguntas com profundidade, ela √© **extremamente insuficiente e gen√©rica**. N√£o aborda os m√∫ltiplos aspectos, a complexidade ou as compara√ß√µes que as suas perguntas exigiam.\n",
        "\n",
        "3.  **Profundidade da Resposta:** A resposta √© **muito superficial** para uma pergunta t√©cnica. Em um contexto de entrevista ou avalia√ß√£o t√©cnica, espera-se que um candidato v√° al√©m de uma defini√ß√£o b√°sica e explique o *porqu√™*, o *como*, as *implica√ß√µes* e os *exemplos*.\n",
        "\n",
        "**Em resumo:**\n",
        "\n",
        "*   **A afirma√ß√£o \"√â indicado para grandes volumes de dados n√£o estruturados\" √© tecnicamente correta.**\n",
        "*   **Como resposta √†s suas 3 perguntas t√©cnicas geradas, √© completamente inadequada e superficial.** Ela n√£o demonstra a compreens√£o t√©cnica aprofundada esperada.\n",
        "\n",
        "**Sugest√£o de Feedback para o Candidato:**\n",
        "\n",
        "\"Sua afirma√ß√£o de que um banco NoSQL '√© indicado para grandes volumes de dados n√£o estruturados' est√° **correta** e capta uma das motiva√ß√µes chave para a sua ado√ß√£o. Essa √©, de facto, uma caracter√≠stica distintiva e um cen√°rio de uso fundamental para muitas solu√ß√µes NoSQL.\\n\\nNo entanto, para o n√≠vel de profundidade esperado em uma pergunta t√©cnica (e especialmente se a inten√ß√£o era responder a uma das tr√™s perguntas propostas, como as sobre categorias, Teorema CAP ou modelagem de dados), essa resposta √© **muito gen√©rica e superficial**.\\n\\nEm um contexto t√©cnico, esperamos que voc√™ **elabore** sobre o que isso significa na pr√°tica. Por exemplo, voc√™ poderia explicar:\n",
        "*   **Por que** os bancos NoSQL s√£o mais adequados para dados n√£o estruturados do que os bancos relacionais? (Mencionar flexibilidade de esquema, escalabilidade horizontal, etc.)\n",
        "*   Quais s√£o as **vantagens e desafios** de lidar com grandes volumes de dados n√£o estruturados em um NoSQL?\n",
        "*   Poderia dar **exemplos** de tipos de dados n√£o estruturados (logs, dados de sensores, posts de redes sociais) e como diferentes tipos de NoSQL (documento, chave-valor, colunar) podem ser usados para eles.\n",
        "*   Como isso **impacta** a forma como os dados s√£o armazenados, indexados e consultados em compara√ß√£o com um ambiente relacional.\n",
        "\n",
        "Aprofundar nesses pontos demonstraria uma compreens√£o t√©cnica muito mais completa.\"\n",
        "A resposta do candidato: \"Exemplo: MongoDB.\"\n",
        "\n",
        "---\n",
        "\n",
        "**Avalia√ß√£o da Resposta:**\n",
        "\n",
        "1.  **Correc√ß√£o da Afirma√ß√£o:** A men√ß√£o a \"MongoDB\" est√° **correta** como um exemplo de um banco de dados NoSQL. Especificamente, o MongoDB √© um banco de dados NoSQL do tipo **orientado a documentos**.\n",
        "\n",
        "2.  **Contexto da Pergunta:** A pergunta era complexa e multifacetada, exigindo:\n",
        "    *   A identifica√ß√£o das **principais categorias** de bancos de dados NoSQL (Chave-Valor, Documento, Colunar, Grafo).\n",
        "    *   Os **cen√°rios de uso t√≠picos** para **cada uma** dessas categorias.\n",
        "    *   Uma **compara√ß√£o** da adequa√ß√£o dessas categorias em rela√ß√£o aos **bancos de dados relacionais tradicionais**.\n",
        "\n",
        "    A resposta do candidato, \"Exemplo: MongoDB\", aborda apenas uma pequena parte de uma das categorias (o tipo \"Documento\" tem MongoDB como um exemplo), mas n√£o descreve a categoria, seus cen√°rios de uso ou compara√ß√µes. Portanto, como resposta √† pergunta formulada, √© **completamente insuficiente e n√£o demonstra a compreens√£o esperada** dos m√∫ltiplos aspectos solicitados.\n",
        "\n",
        "3.  **Profundidade da Resposta:** A resposta √© **extremamente superficial**. Em um contexto t√©cnico, espera-se que um candidato v√° muito al√©m de apenas citar um exemplo, elaborando sobre os conceitos, aplica√ß√µes, vantagens e desvantagens de cada tipo de NoSQL.\n",
        "\n",
        "**Em resumo:**\n",
        "\n",
        "*   A men√ß√£o a \"MongoDB\" √© um exemplo v√°lido de um banco NoSQL (especificamente, orientado a documentos).\n",
        "*   Por√©m, como resposta √† pergunta 1, que exige uma descri√ß√£o das categorias, seus cen√°rios de uso e compara√ß√£o com bancos relacionais, √© **totalmente inadequada e n√£o demonstra o conhecimento t√©cnico aprofundado esperado**.\n",
        "\n",
        "---\n",
        "\n",
        "**Sugest√£o de Feedback para o Candidato:**\n",
        "\n",
        "\"Sua men√ß√£o a 'MongoDB' est√° **correta** como um exemplo de banco de dados NoSQL. De facto, ele √© um dos bancos de dados NoSQL mais populares e se encaixa na categoria de **bancos de dados orientados a documentos**.\"\n",
        "\n",
        "\"No entanto, a pergunta pedia uma discuss√£o **muito mais abrangente** sobre as diferentes categorias de bancos de dados NoSQL. Esperava-se que voc√™ identificasse e descrevesse as **principais categorias** (como Chave-Valor, Documento, Colunar e Grafo), e para **cada categoria**, discutisse seus **cen√°rios de uso t√≠picos** e, crucialmente, fizesse uma **compara√ß√£o** sobre quando cada uma delas √© mais adequada *em rela√ß√£o aos bancos de dados relacionais tradicionais*.\"\n",
        "\n",
        "\"Para o n√≠vel de profundidade esperado em uma pergunta t√©cnica, seria importante **elaborar** sobre cada tipo. Por exemplo, ao mencionar o MongoDB (Documento), voc√™ poderia ter explicado que ele √© ideal para dados semi-estruturados, documentos flex√≠veis como JSON, cat√°logos de produtos, perfis de usu√°rio, etc., destacando a flexibilidade de esquema como uma vantagem em compara√ß√£o com a rigidez de um esquema relacional.\"\n",
        "\n",
        "\"Uma resposta completa demonstraria sua capacidade de diferenciar as tecnologias NoSQL, entender seus pontos fortes e fracos, e aplic√°-los a problemas do mundo real, o que √© essencial para um n√≠vel t√©cnico.\""
      ],
      "metadata": {
        "id": "R2gF3-QXvMKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Classe para an√°lise comparativa de tecnologias com relat√≥rio final\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class ComparadorTecnologico:\n",
        "    def __init__(self, agent_id=\"comparador\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id)\n",
        "\n",
        "    def comparar(self, tecnologia1, tecnologia2):\n",
        "        prompt = f\"Compare de forma detalhada as tecnologias: {tecnologia1} e {tecnologia2}, citando vantagens, desvantagens e poss√≠veis aplica√ß√µes.\"\n",
        "        return self.agent.chat(prompt)\n",
        "\n",
        "comparador = ComparadorTecnologico()\n",
        "print(comparador.comparar(\"TensorFlow\", \"PyTorch\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wRcu3gl2vgI4",
        "outputId": "8c1f2e2c-2db0-4af1-bb9a-f81e728cc0ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m21:05:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[comparador]\u001b[0m | \u001b[1m‚úÖ Agente inicializado - ID: comparador, Modelo: gemini-2.5-flash\u001b[0m\n",
            "\u001b[32m21:05:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[comparador]\u001b[0m | \u001b[1müí¨ Chat: Compare de forma detalhada as tecnologias: TensorF... ‚Üí Com certeza! TensorFlow e PyTorch s√£o as duas bibl...\u001b[0m\n",
            "Com certeza! TensorFlow e PyTorch s√£o as duas bibliotecas de deep learning mais populares e poderosas do mercado. Ambas permitem construir, treinar e implantar modelos complexos, mas possuem filosofias de design e pontos fortes distintos.\n",
            "\n",
            "Vamos compar√°-las detalhadamente:\n",
            "\n",
            "---\n",
            "\n",
            "## **TensorFlow**\n",
            "\n",
            "**Origem:** Desenvolvido e mantido pelo Google.\n",
            "**Lan√ßamento:** 2015\n",
            "**Vers√£o Atual Relevante:** TensorFlow 2.x (que incorporou Keras e adotou execu√ß√£o eager por padr√£o, aproximando-se do PyTorch em termos de usabilidade).\n",
            "\n",
            "### **Filosofia / Modelo de Execu√ß√£o (TensorFlow 2.x):**\n",
            "\n",
            "Historicamente, o TensorFlow era conhecido por sua **arquitetura de grafo est√°tico**. Isso significava que voc√™ precisava definir todo o grafo computacional (todas as opera√ß√µes e como elas se conectam) *antes* de executar qualquer computa√ß√£o.\n",
            "Com o TensorFlow 2.x, a **execu√ß√£o eager (din√¢mica)** se tornou o padr√£o. Isso permite que as opera√ß√µes sejam executadas imediatamente e os valores sejam retornados, tornando o desenvolvimento e a depura√ß√£o muito mais intuitivos e semelhantes ao Python tradicional. No entanto, ele ainda oferece `tf.function` para compilar partes do c√≥digo Python em grafos est√°ticos otimizados para desempenho e deployment.\n",
            "\n",
            "### **Vantagens do TensorFlow:**\n",
            "\n",
            "1.  **Ecossistema Abrangente e Maduro:** O TensorFlow possui um ecossistema gigantesco, incluindo:\n",
            "    *   **TensorFlow Serving:** Para deployment eficiente de modelos em produ√ß√£o.\n",
            "    *   **TensorFlow Lite:** Para modelos em dispositivos m√≥veis e embarcados (edge devices).\n",
            "    *   **TensorFlow.js:** Para executar modelos no navegador ou em Node.js.\n",
            "    *   **TensorFlow Extended (TFX):** Uma plataforma completa para produ√ß√£o de ML (MLOps), abrangendo desde a ingest√£o de dados at√© o monitoramento do modelo.\n",
            "    *   **TensorBoard:** Uma poderosa ferramenta de visualiza√ß√£o para monitorar m√©tricas de treinamento, visualizar grafos e embeddings.\n",
            "2.  **Escalabilidade e Produ√ß√£o:** Historicamente, o TensorFlow era a escolha dominante para grandes implementa√ß√µes em escala de produ√ß√£o e sistemas distribu√≠dos complexos. Seu design original de grafo est√°tico permitia otimiza√ß√µes de compila√ß√£o muito robustas. Embora o PyTorch tenha avan√ßado muito aqui, o TF ainda √© uma refer√™ncia em MLOps e deployment.\n",
            "3.  **Suporte Corporativo Robusto:** Ser desenvolvido pelo Google garante um forte suporte corporativo, vastos recursos e integra√ß√£o nativa com tecnologias do Google Cloud (TPUs, Google Kubernetes Engine, etc.).\n",
            "4.  **Integra√ß√£o Keras:** Keras √© uma API de alto n√≠vel extremamente popular e f√°cil de usar. No TF 2.x, Keras foi totalmente integrado como a API padr√£o para constru√ß√£o de modelos, tornando o TensorFlow muito mais acess√≠vel e produtivo para iniciantes e desenvolvedores que buscam agilidade.\n",
            "5.  **Otimiza√ß√£o para Hardware Espec√≠fico:** Forte suporte para TPUs (Tensor Processing Units) do Google, que podem oferecer acelera√ß√£o significativa para certos tipos de cargas de trabalho.\n",
            "\n",
            "### **Desvantagens do TensorFlow:**\n",
            "\n",
            "1.  **Curva de Aprendizagem (Hist√≥rico):** Antes do TF 2.x, sua natureza de grafo est√°tico tornava a depura√ß√£o mais complexa e a API, mais verbosa e menos \"Pythonic\" para muitos. Embora tenha melhorado drasticamente, alguns ainda podem ach√°-lo mais complexo para controle de baixo n√≠vel em compara√ß√£o com PyTorch.\n",
            "2.  **Menos \"Pythonic\" (para alguns casos):** Mesmo com o eager execution, alguns desenvolvedores acham que o fluxo de trabalho pode ser menos alinhado com as pr√°ticas de codifica√ß√£o Python idiom√°ticas quando comparado ao PyTorch, especialmente em cen√°rios muito customizados.\n",
            "3.  **Sobrepeso para Projetos Pequenos:** Para prot√≥tipos r√°pidos ou projetos menores, a infraestrutura robusta e o ecossistema completo do TensorFlow podem parecer um pouco \"demais\", tornando o PyTorch uma op√ß√£o mais leve e r√°pida para come√ßar.\n",
            "\n",
            "### **Aplica√ß√µes do TensorFlow:**\n",
            "\n",
            "*   **Sistemas de Recomenda√ß√£o em Escala:** Utilizado por grandes empresas para personalizar experi√™ncias de usu√°rio.\n",
            "*   **Processamento de Linguagem Natural (NLP):** Treinamento de modelos de linguagem como BERT, T5 e outros grandes modelos para chatbots, tradu√ß√£o, an√°lise de sentimento.\n",
            "*   **Vis√£o Computacional:** Detec√ß√£o de objetos, reconhecimento facial, segmenta√ß√£o de imagens em larga escala (por exemplo, em carros aut√¥nomos ou monitoramento de seguran√ßa).\n",
            "*   **Previs√£o de S√©ries Temporais:** Modelagem de dados financeiros, previs√£o de demanda, an√°lise de sensores.\n",
            "*   **Desenvolvimento de Modelos para Edge Devices:** Com TensorFlow Lite, √© a escolha ideal para integrar IA em smartphones, IoT e outros dispositivos com recursos limitados.\n",
            "*   **Grandes Implanta√ß√µes em Nuvem:** Se beneficiando da integra√ß√£o com GCP e TPUs.\n",
            "\n",
            "---\n",
            "\n",
            "## **PyTorch**\n",
            "\n",
            "**Origem:** Desenvolvido e mantido pelo Facebook (agora Meta).\n",
            "**Lan√ßamento:** 2016\n",
            "\n",
            "### **Filosofia / Modelo de Execu√ß√£o:**\n",
            "\n",
            "PyTorch √© constru√≠do em torno de uma **arquitetura de grafo din√¢mico**, tamb√©m conhecida como **execu√ß√£o eager por padr√£o**. Isso significa que o grafo computacional √© constru√≠do em tempo de execu√ß√£o, √† medida que cada opera√ß√£o √© executada. √â semelhante √† forma como o Python padr√£o funciona, tornando-o muito intuitivo para os desenvolvedores Python. A biblioteca `autograd` do PyTorch √© a espinha dorsal para a diferencia√ß√£o autom√°tica.\n",
            "\n",
            "### **Vantagens do PyTorch:**\n",
            "\n",
            "1.  **Pythonic e Intuitivo:** Sua API √© extremamente \"Pythonic\", o que significa que o c√≥digo se parece e se comporta como c√≥digo Python normal. Isso facilita o aprendizado para desenvolvedores Python e torna o prototipagem e a depura√ß√£o mais r√°pidos.\n",
            "2.  **Grafo de Computa√ß√£o Din√¢mico:** A principal vantagem. Permite flexibilidade incompar√°vel, o que √© crucial para modelos de pesquisa com estruturas de dados vari√°veis (como NLP com sequ√™ncias de comprimento vari√°vel) ou modelos que precisam de l√≥gica condicional que muda durante a execu√ß√£o.\n",
            "3.  **Facilidade de Depura√ß√£o:** Gra√ßas ao grafo din√¢mico, voc√™ pode usar depuradores Python padr√£o (como `pdb`) para inspecionar o c√≥digo a qualquer momento, o que n√£o era trivial com os grafos est√°ticos do TensorFlow.\n",
            "4.  **Prototipagem R√°pida e Pesquisa:** Devido √† sua flexibilidade e facilidade de uso, PyTorch se tornou a ferramenta preferida na comunidade de pesquisa e acad√™mica. Muitos dos artigos de ponta em ML implementam seus modelos inicialmente em PyTorch.\n",
            "5.  **Comunidade Ativa e Crescente:** A comunidade de PyTorch √© extremamente vibrante, especialmente em pesquisa. H√° muitos tutoriais, exemplos e implementa√ß√µes de artigos dispon√≠veis.\n",
            "6.  **TorchScript:** Permite a transi√ß√£o de modelos do modo eager para um modo de grafo est√°tico otimizado para produ√ß√£o, preenchendo a lacuna que existia em rela√ß√£o ao TensorFlow para deployment.\n",
            "7.  **`torch.compile` (futuro/recente):** Uma nova funcionalidade para otimizar e acelerar ainda mais o treinamento e a infer√™ncia, compilando o c√≥digo PyTorch para opera√ß√µes mais eficientes.\n",
            "\n",
            "### **Desvantagens do PyTorch:**\n",
            "\n",
            "1.  **Maturidade do Ecossistema de Produ√ß√£o (Hist√≥rico):** Embora tenha melhorado drasticamente com TorchScript, PyTorch Mobile e bibliotecas como `accelerate` da Hugging Face, ele historicamente tinha menos ferramentas robustas para deployment em larga escala e MLOps em compara√ß√£o com o ecossystema TFX do TensorFlow. Essa lacuna est√° diminuindo rapidamente.\n",
            "2.  **Menos Ferramentas \"Out-of-the-box\" para Deployment:** Embora TorchScript ajude, o TensorFlow ainda possui uma vantagem em ferramentas como TensorFlow Serving, TensorFlow Lite, TensorFlow.js, que s√£o mais maduras e integradas para cen√°rios espec√≠ficos.\n",
            "3.  **Visualiza√ß√£o:** Embora voc√™ possa usar TensorBoard com PyTorch (via `torch.utils.tensorboard`), as ferramentas nativas de visualiza√ß√£o podem n√£o ser t√£o completas ou integradas quanto as do TensorFlow para certos aspectos.\n",
            "\n",
            "### **Aplica√ß√µes do PyTorch:**\n",
            "\n",
            "*   **Pesquisa e Desenvolvimento:** Ideal para experimentar novas arquiteturas de rede e algoritmos de aprendizado de m√°quina.\n",
            "*   **Processamento de Linguagem Natural (NLP):** Particularmente eficaz para modelos com estruturas din√¢micas, como muitos modelos Transformer e seq2seq, e para bibliotecas como Hugging Face Transformers.\n",
            "*   **Vis√£o Computacional:** Modelos para classifica√ß√£o de imagens, detec√ß√£o de objetos e segmenta√ß√£o, especialmente em pesquisa e customiza√ß√£o.\n",
            "*   **Reinforcement Learning:** A flexibilidade do grafo din√¢mico √© muito √∫til para algoritmos de RL que frequentemente envolvem l√≥gica complexa e que muda dinamicamente.\n",
            "*   **Gera√ß√£o de Conte√∫do:** Modelos generativos como GANs e VAEs, onde a flexibilidade do grafo √© ben√©fica.\n",
            "*   **Projetos Acad√™micos e Startups:** Onde a agilidade no desenvolvimento e a capacidade de experimentar rapidamente s√£o cruciais.\n",
            "\n",
            "---\n",
            "\n",
            "## **Conclus√£o e Quando Escolher Qual:**\n",
            "\n",
            "Tanto TensorFlow quanto PyTorch s√£o ferramentas fant√°sticas e extremamente poderosas para deep learning. A rivalidade inicial de \"grafo est√°tico vs. grafo din√¢mico\" diminuiu consideravelmente com o TensorFlow 2.x adotando o eager execution e o PyTorch introduzindo TorchScript para otimiza√ß√£o em produ√ß√£o. H√° uma **converg√™ncia significativa** entre as duas.\n",
            "\n",
            "*   **Escolha TensorFlow se:**\n",
            "    *   Voc√™ precisa de uma solu√ß√£o **robusta e comprovada para deployment em larga escala e produ√ß√£o (MLOps)**, especialmente se estiver construindo um produto que ser√° executado em diversas plataformas (web, mobile, edge).\n",
            "    *   Sua equipe j√° tem experi√™ncia com o ecossistema Google Cloud e TPUs.\n",
            "    *   Voc√™ aprecia uma **API de alto n√≠vel mais \"opiniosa\" (Keras)** para construir modelos rapidamente.\n",
            "    *   Voc√™ est√° trabalhando em um ambiente corporativo grande que valoriza um ecossistema completo e suporte empresarial.\n",
            "\n",
            "*   **Escolha PyTorch se:**\n",
            "    *   Voc√™ prioriza a **facilidade de uso, prototipagem r√°pida e depura√ß√£o intuitiva**, especialmente se voc√™ vem de um background de desenvolvimento Python.\n",
            "    *   Voc√™ est√° envolvido em **pesquisa e desenvolvimento** de ponta, onde a flexibilidade para experimentar novas arquiteturas √© crucial.\n",
            "    *   Sua equipe valoriza uma experi√™ncia de codifica√ß√£o mais **\"Pythonic\"** e transparente.\n",
            "    *   Voc√™ trabalha com modelos que exigem **l√≥gica de grafo altamente din√¢mica ou estruturas de dados vari√°veis**.\n",
            "\n",
            "Muitas empresas e pesquisadores acabam usando ambos, escolhendo a ferramenta mais adequada para cada fase ou aspecto do projeto. A melhor escolha, no final das contas, depende dos requisitos espec√≠ficos do seu projeto, da experi√™ncia da sua equipe e das suas prefer√™ncias pessoais.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com certeza! TensorFlow e PyTorch s√£o as duas bibliotecas de deep learning mais populares e poderosas do mercado. Ambas permitem construir, treinar e implantar modelos complexos, mas possuem filosofias de design e pontos fortes distintos.\n",
        "\n",
        "Vamos compar√°-las detalhadamente:\n",
        "\n",
        "---\n",
        "\n",
        "## **TensorFlow**\n",
        "\n",
        "**Origem:** Desenvolvido e mantido pelo Google.\n",
        "**Lan√ßamento:** 2015\n",
        "**Vers√£o Atual Relevante:** TensorFlow 2.x (que incorporou Keras e adotou execu√ß√£o eager por padr√£o, aproximando-se do PyTorch em termos de usabilidade).\n",
        "\n",
        "### **Filosofia / Modelo de Execu√ß√£o (TensorFlow 2.x):**\n",
        "\n",
        "Historicamente, o TensorFlow era conhecido por sua **arquitetura de grafo est√°tico**. Isso significava que voc√™ precisava definir todo o grafo computacional (todas as opera√ß√µes e como elas se conectam) *antes* de executar qualquer computa√ß√£o.\n",
        "Com o TensorFlow 2.x, a **execu√ß√£o eager (din√¢mica)** se tornou o padr√£o. Isso permite que as opera√ß√µes sejam executadas imediatamente e os valores sejam retornados, tornando o desenvolvimento e a depura√ß√£o muito mais intuitivos e semelhantes ao Python tradicional. No entanto, ele ainda oferece `tf.function` para compilar partes do c√≥digo Python em grafos est√°ticos otimizados para desempenho e deployment.\n",
        "\n",
        "### **Vantagens do TensorFlow:**\n",
        "\n",
        "1.  **Ecossistema Abrangente e Maduro:** O TensorFlow possui um ecossistema gigantesco, incluindo:\n",
        "    *   **TensorFlow Serving:** Para deployment eficiente de modelos em produ√ß√£o.\n",
        "    *   **TensorFlow Lite:** Para modelos em dispositivos m√≥veis e embarcados (edge devices).\n",
        "    *   **TensorFlow.js:** Para executar modelos no navegador ou em Node.js.\n",
        "    *   **TensorFlow Extended (TFX):** Uma plataforma completa para produ√ß√£o de ML (MLOps), abrangendo desde a ingest√£o de dados at√© o monitoramento do modelo.\n",
        "    *   **TensorBoard:** Uma poderosa ferramenta de visualiza√ß√£o para monitorar m√©tricas de treinamento, visualizar grafos e embeddings.\n",
        "2.  **Escalabilidade e Produ√ß√£o:** Historicamente, o TensorFlow era a escolha dominante para grandes implementa√ß√µes em escala de produ√ß√£o e sistemas distribu√≠dos complexos. Seu design original de grafo est√°tico permitia otimiza√ß√µes de compila√ß√£o muito robustas. Embora o PyTorch tenha avan√ßado muito aqui, o TF ainda √© uma refer√™ncia em MLOps e deployment.\n",
        "3.  **Suporte Corporativo Robusto:** Ser desenvolvido pelo Google garante um forte suporte corporativo, vastos recursos e integra√ß√£o nativa com tecnologias do Google Cloud (TPUs, Google Kubernetes Engine, etc.).\n",
        "4.  **Integra√ß√£o Keras:** Keras √© uma API de alto n√≠vel extremamente popular e f√°cil de usar. No TF 2.x, Keras foi totalmente integrado como a API padr√£o para constru√ß√£o de modelos, tornando o TensorFlow muito mais acess√≠vel e produtivo para iniciantes e desenvolvedores que buscam agilidade.\n",
        "5.  **Otimiza√ß√£o para Hardware Espec√≠fico:** Forte suporte para TPUs (Tensor Processing Units) do Google, que podem oferecer acelera√ß√£o significativa para certos tipos de cargas de trabalho.\n",
        "\n",
        "### **Desvantagens do TensorFlow:**\n",
        "\n",
        "1.  **Curva de Aprendizagem (Hist√≥rico):** Antes do TF 2.x, sua natureza de grafo est√°tico tornava a depura√ß√£o mais complexa e a API, mais verbosa e menos \"Pythonic\" para muitos. Embora tenha melhorado drasticamente, alguns ainda podem ach√°-lo mais complexo para controle de baixo n√≠vel em compara√ß√£o com PyTorch.\n",
        "2.  **Menos \"Pythonic\" (para alguns casos):** Mesmo com o eager execution, alguns desenvolvedores acham que o fluxo de trabalho pode ser menos alinhado com as pr√°ticas de codifica√ß√£o Python idiom√°ticas quando comparado ao PyTorch, especialmente em cen√°rios muito customizados.\n",
        "3.  **Sobrepeso para Projetos Pequenos:** Para prot√≥tipos r√°pidos ou projetos menores, a infraestrutura robusta e o ecossistema completo do TensorFlow podem parecer um pouco \"demais\", tornando o PyTorch uma op√ß√£o mais leve e r√°pida para come√ßar.\n",
        "\n",
        "### **Aplica√ß√µes do TensorFlow:**\n",
        "\n",
        "*   **Sistemas de Recomenda√ß√£o em Escala:** Utilizado por grandes empresas para personalizar experi√™ncias de usu√°rio.\n",
        "*   **Processamento de Linguagem Natural (NLP):** Treinamento de modelos de linguagem como BERT, T5 e outros grandes modelos para chatbots, tradu√ß√£o, an√°lise de sentimento.\n",
        "*   **Vis√£o Computacional:** Detec√ß√£o de objetos, reconhecimento facial, segmenta√ß√£o de imagens em larga escala (por exemplo, em carros aut√¥nomos ou monitoramento de seguran√ßa).\n",
        "*   **Previs√£o de S√©ries Temporais:** Modelagem de dados financeiros, previs√£o de demanda, an√°lise de sensores.\n",
        "*   **Desenvolvimento de Modelos para Edge Devices:** Com TensorFlow Lite, √© a escolha ideal para integrar IA em smartphones, IoT e outros dispositivos com recursos limitados.\n",
        "*   **Grandes Implanta√ß√µes em Nuvem:** Se beneficiando da integra√ß√£o com GCP e TPUs.\n",
        "\n",
        "---\n",
        "\n",
        "## **PyTorch**\n",
        "\n",
        "**Origem:** Desenvolvido e mantido pelo Facebook (agora Meta).\n",
        "**Lan√ßamento:** 2016\n",
        "\n",
        "### **Filosofia / Modelo de Execu√ß√£o:**\n",
        "\n",
        "PyTorch √© constru√≠do em torno de uma **arquitetura de grafo din√¢mico**, tamb√©m conhecida como **execu√ß√£o eager por padr√£o**. Isso significa que o grafo computacional √© constru√≠do em tempo de execu√ß√£o, √† medida que cada opera√ß√£o √© executada. √â semelhante √† forma como o Python padr√£o funciona, tornando-o muito intuitivo para os desenvolvedores Python. A biblioteca `autograd` do PyTorch √© a espinha dorsal para a diferencia√ß√£o autom√°tica.\n",
        "\n",
        "### **Vantagens do PyTorch:**\n",
        "\n",
        "1.  **Pythonic e Intuitivo:** Sua API √© extremamente \"Pythonic\", o que significa que o c√≥digo se parece e se comporta como c√≥digo Python normal. Isso facilita o aprendizado para desenvolvedores Python e torna o prototipagem e a depura√ß√£o mais r√°pidos.\n",
        "2.  **Grafo de Computa√ß√£o Din√¢mico:** A principal vantagem. Permite flexibilidade incompar√°vel, o que √© crucial para modelos de pesquisa com estruturas de dados vari√°veis (como NLP com sequ√™ncias de comprimento vari√°vel) ou modelos que precisam de l√≥gica condicional que muda durante a execu√ß√£o.\n",
        "3.  **Facilidade de Depura√ß√£o:** Gra√ßas ao grafo din√¢mico, voc√™ pode usar depuradores Python padr√£o (como `pdb`) para inspecionar o c√≥digo a qualquer momento, o que n√£o era trivial com os grafos est√°ticos do TensorFlow.\n",
        "4.  **Prototipagem R√°pida e Pesquisa:** Devido √† sua flexibilidade e facilidade de uso, PyTorch se tornou a ferramenta preferida na comunidade de pesquisa e acad√™mica. Muitos dos artigos de ponta em ML implementam seus modelos inicialmente em PyTorch.\n",
        "5.  **Comunidade Ativa e Crescente:** A comunidade de PyTorch √© extremamente vibrante, especialmente em pesquisa. H√° muitos tutoriais, exemplos e implementa√ß√µes de artigos dispon√≠veis.\n",
        "6.  **TorchScript:** Permite a transi√ß√£o de modelos do modo eager para um modo de grafo est√°tico otimizado para produ√ß√£o, preenchendo a lacuna que existia em rela√ß√£o ao TensorFlow para deployment.\n",
        "7.  **`torch.compile` (futuro/recente):** Uma nova funcionalidade para otimizar e acelerar ainda mais o treinamento e a infer√™ncia, compilando o c√≥digo PyTorch para opera√ß√µes mais eficientes.\n",
        "\n",
        "### **Desvantagens do PyTorch:**\n",
        "\n",
        "1.  **Maturidade do Ecossistema de Produ√ß√£o (Hist√≥rico):** Embora tenha melhorado drasticamente com TorchScript, PyTorch Mobile e bibliotecas como `accelerate` da Hugging Face, ele historicamente tinha menos ferramentas robustas para deployment em larga escala e MLOps em compara√ß√£o com o ecossystema TFX do TensorFlow. Essa lacuna est√° diminuindo rapidamente.\n",
        "2.  **Menos Ferramentas \"Out-of-the-box\" para Deployment:** Embora TorchScript ajude, o TensorFlow ainda possui uma vantagem em ferramentas como TensorFlow Serving, TensorFlow Lite, TensorFlow.js, que s√£o mais maduras e integradas para cen√°rios espec√≠ficos.\n",
        "3.  **Visualiza√ß√£o:** Embora voc√™ possa usar TensorBoard com PyTorch (via `torch.utils.tensorboard`), as ferramentas nativas de visualiza√ß√£o podem n√£o ser t√£o completas ou integradas quanto as do TensorFlow para certos aspectos.\n",
        "\n",
        "### **Aplica√ß√µes do PyTorch:**\n",
        "\n",
        "*   **Pesquisa e Desenvolvimento:** Ideal para experimentar novas arquiteturas de rede e algoritmos de aprendizado de m√°quina.\n",
        "*   **Processamento de Linguagem Natural (NLP):** Particularmente eficaz para modelos com estruturas din√¢micas, como muitos modelos Transformer e seq2seq, e para bibliotecas como Hugging Face Transformers.\n",
        "*   **Vis√£o Computacional:** Modelos para classifica√ß√£o de imagens, detec√ß√£o de objetos e segmenta√ß√£o, especialmente em pesquisa e customiza√ß√£o.\n",
        "*   **Reinforcement Learning:** A flexibilidade do grafo din√¢mico √© muito √∫til para algoritmos de RL que frequentemente envolvem l√≥gica complexa e que muda dinamicamente.\n",
        "*   **Gera√ß√£o de Conte√∫do:** Modelos generativos como GANs e VAEs, onde a flexibilidade do grafo √© ben√©fica.\n",
        "*   **Projetos Acad√™micos e Startups:** Onde a agilidade no desenvolvimento e a capacidade de experimentar rapidamente s√£o cruciais.\n",
        "\n",
        "---\n",
        "\n",
        "## **Conclus√£o e Quando Escolher Qual:**\n",
        "\n",
        "Tanto TensorFlow quanto PyTorch s√£o ferramentas fant√°sticas e extremamente poderosas para deep learning. A rivalidade inicial de \"grafo est√°tico vs. grafo din√¢mico\" diminuiu consideravelmente com o TensorFlow 2.x adotando o eager execution e o PyTorch introduzindo TorchScript para otimiza√ß√£o em produ√ß√£o. H√° uma **converg√™ncia significativa** entre as duas.\n",
        "\n",
        "*   **Escolha TensorFlow se:**\n",
        "    *   Voc√™ precisa de uma solu√ß√£o **robusta e comprovada para deployment em larga escala e produ√ß√£o (MLOps)**, especialmente se estiver construindo um produto que ser√° executado em diversas plataformas (web, mobile, edge).\n",
        "    *   Sua equipe j√° tem experi√™ncia com o ecossistema Google Cloud e TPUs.\n",
        "    *   Voc√™ aprecia uma **API de alto n√≠vel mais \"opiniosa\" (Keras)** para construir modelos rapidamente.\n",
        "    *   Voc√™ est√° trabalhando em um ambiente corporativo grande que valoriza um ecossistema completo e suporte empresarial.\n",
        "\n",
        "*   **Escolha PyTorch se:**\n",
        "    *   Voc√™ prioriza a **facilidade de uso, prototipagem r√°pida e depura√ß√£o intuitiva**, especialmente se voc√™ vem de um background de desenvolvimento Python.\n",
        "    *   Voc√™ est√° envolvido em **pesquisa e desenvolvimento** de ponta, onde a flexibilidade para experimentar novas arquiteturas √© crucial.\n",
        "    *   Sua equipe valoriza uma experi√™ncia de codifica√ß√£o mais **\"Pythonic\"** e transparente.\n",
        "    *   Voc√™ trabalha com modelos que exigem **l√≥gica de grafo altamente din√¢mica ou estruturas de dados vari√°veis**.\n",
        "\n",
        "Muitas empresas e pesquisadores acabam usando ambos, escolhendo a ferramenta mais adequada para cada fase ou aspecto do projeto. A melhor escolha, no final das contas, depende dos requisitos espec√≠ficos do seu projeto, da experi√™ncia da sua equipe e das suas prefer√™ncias pessoais."
      ],
      "metadata": {
        "id": "0O-cHQ56xteQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class AtendimentoCliente:\n",
        "    def __init__(self, agent_id=\"atendimento\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id)\n",
        "        self.contexto = []\n",
        "\n",
        "    def registrar_interacao(self, mensagem):\n",
        "        self.contexto.append(mensagem)\n",
        "        resposta = self.agent.chat(f\"Contexto: {self.contexto}\\nUsu√°rio: {mensagem}\")\n",
        "        self.contexto.append(resposta)\n",
        "        return resposta\n",
        "\n",
        "atendimento = AtendimentoCliente()\n",
        "print(atendimento.registrar_interacao(\"Meu pedido est√° atrasado.\"))\n",
        "print(atendimento.registrar_interacao(\"Quero saber o status da entrega.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "yQztWPLIx6XR",
        "outputId": "455f9f96-5ccf-4e13-b396-d5fdc93e3f32"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m21:17:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[atendimento]\u001b[0m | \u001b[1m‚úÖ Agente inicializado - ID: atendimento, Modelo: gemini-2.5-flash\u001b[0m\n",
            "\u001b[32m21:17:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[atendimento]\u001b[0m | \u001b[1müí¨ Chat: Contexto: ['Meu pedido est√° atrasado.']\n",
            "Usu√°rio: M... ‚Üí Lamento ouvir que seu pedido est√° atrasado.\n",
            "\n",
            "Para ...\u001b[0m\n",
            "Lamento ouvir que seu pedido est√° atrasado.\n",
            "\n",
            "Para que eu possa verificar o que aconteceu e te dar uma atualiza√ß√£o, por favor, me informe o n√∫mero do seu pedido.\n",
            "\u001b[32m21:17:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[atendimento]\u001b[0m | \u001b[1müí¨ Chat: Contexto: ['Meu pedido est√° atrasado.', 'Lamento o... ‚Üí Para que eu possa verificar o status da sua entreg...\u001b[0m\n",
            "Para que eu possa verificar o status da sua entrega e te dar uma atualiza√ß√£o, por favor, me informe o n√∫mero do seu pedido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Classe que executa an√°lise de sentimentos em lote\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class AnaliseSentimentos:\n",
        "    def __init__(self, agent_id=\"sentimentos\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id)\n",
        "\n",
        "    def analisar_lote(self, textos):\n",
        "        resultados = []\n",
        "        for texto in textos:\n",
        "            prompt = f\"Classifique o sentimento (positivo, negativo, neutro) do seguinte texto:\\n{texto}\"\n",
        "            resultados.append(self.agent.chat(prompt))\n",
        "        return resultados\n",
        "\n",
        "comentarios = [\n",
        "    \"O produto √© excelente! Mas faltou um engrediente\",\n",
        "    \"N√£o gostei do atendimento.\",\n",
        "    \"Entrega dentro do prazo.\"\n",
        "]\n",
        "analista = AnaliseSentimentos()\n",
        "print(analista.analisar_lote(comentarios))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "LH05NznbyzIg",
        "outputId": "f98d3ab2-e2b8-41bc-e824-2545e237607c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m21:19:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[sentimentos]\u001b[0m | \u001b[1m‚úÖ Agente inicializado - ID: sentimentos, Modelo: gemini-2.5-flash\u001b[0m\n",
            "\u001b[32m21:19:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[sentimentos]\u001b[0m | \u001b[1müí¨ Chat: Classifique o sentimento (positivo, negativo, neut... ‚Üí Positivo...\u001b[0m\n",
            "\u001b[32m21:19:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[sentimentos]\u001b[0m | \u001b[1müí¨ Chat: Classifique o sentimento (positivo, negativo, neut... ‚Üí Negativo...\u001b[0m\n",
            "\u001b[32m21:19:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[sentimentos]\u001b[0m | \u001b[1müí¨ Chat: Classifique o sentimento (positivo, negativo, neut... ‚Üí Neutro...\u001b[0m\n",
            "['Positivo', 'Negativo', 'Neutro']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Classe para gera√ß√£o automatizada de documenta√ß√£o t√©cnica de c√≥digo\n",
        "from mangaba_ai import MangabaAgent\n",
        "\n",
        "class GeradorDocumentacao:\n",
        "    def __init__(self, agent_id=\"docgen\"):\n",
        "        self.agent = MangabaAgent(model=\"gemini-2.5-flash\", agent_id=agent_id)\n",
        "\n",
        "    def documentar_codigo(self, codigo):\n",
        "        prompt = f\"Leia o c√≥digo abaixo e gere uma documenta√ß√£o t√©cnica detalhada, incluindo exemplos de uso:\\n{codigo}\"\n",
        "        return self.agent.chat(prompt)\n",
        "\n",
        "codigo = '''\n",
        "def calcular_media(valores):\n",
        "    \"\"\"Recebe uma lista de n√∫meros e retorna a m√©dia aritm√©tica.\"\"\"\n",
        "    return sum(valores) / len(valores)\n",
        "'''\n",
        "docgen = GeradorDocumentacao()\n",
        "print(docgen.documentar_codigo(codigo))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dWvb87inzRDX",
        "outputId": "18ab9179-2871-4249-c04c-7a32e2dfd19e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m21:19:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[docgen]\u001b[0m | \u001b[1m‚úÖ Agente inicializado - ID: docgen, Modelo: gemini-2.5-flash\u001b[0m\n",
            "\u001b[32m21:20:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mMangabaAgent[docgen]\u001b[0m | \u001b[1müí¨ Chat: Leia o c√≥digo abaixo e gere uma documenta√ß√£o t√©cni... ‚Üí Claro! Abaixo est√° a documenta√ß√£o t√©cnica detalhad...\u001b[0m\n",
            "Claro! Abaixo est√° a documenta√ß√£o t√©cnica detalhada para a fun√ß√£o `calcular_media`, incluindo exemplos de uso.\n",
            "\n",
            "---\n",
            "\n",
            "# Documenta√ß√£o T√©cnica da Fun√ß√£o `calcular_media`\n",
            "\n",
            "## 1. Vis√£o Geral\n",
            "\n",
            "A fun√ß√£o `calcular_media` √© uma utilidade simples e direta projetada para calcular a m√©dia aritm√©tica de uma cole√ß√£o de n√∫meros. Ela recebe uma lista (ou qualquer iter√°vel) de valores num√©ricos e retorna a soma desses valores dividida pela quantidade de elementos. √â ideal para cen√°rios onde √© necess√°rio obter um valor central representativo de um conjunto de dados.\n",
            "\n",
            "## 2. Assinatura da Fun√ß√£o\n",
            "\n",
            "```python\n",
            "def calcular_media(valores):\n",
            "```\n",
            "\n",
            "## 3. Par√¢metros\n",
            "\n",
            "*   **`valores`** (obrigat√≥rio)\n",
            "    *   **Tipo:** `list` (ou qualquer iter√°vel, como `tuple`, `set`, etc.)\n",
            "    *   **Descri√ß√£o:** Uma cole√ß√£o de n√∫meros (inteiros ou decimais) dos quais a m√©dia ser√° calculada.\n",
            "    *   **Restri√ß√µes:**\n",
            "        *   Todos os elementos dentro do iter√°vel devem ser do tipo num√©rico (`int` ou `float`).\n",
            "        *   **N√£o deve ser uma lista vazia.** Se uma lista vazia for fornecida, a fun√ß√£o levantar√° uma exce√ß√£o `ZeroDivisionError`.\n",
            "\n",
            "## 4. Retorno\n",
            "\n",
            "*   **Tipo:** `float`\n",
            "*   **Descri√ß√£o:** A m√©dia aritm√©tica dos n√∫meros fornecidos. O resultado √© sempre um n√∫mero de ponto flutuante, mesmo que todos os valores de entrada sejam inteiros (devido √† opera√ß√£o de divis√£o).\n",
            "\n",
            "## 5. Exce√ß√µes / Erros Potenciais\n",
            "\n",
            "*   **`ZeroDivisionError`**\n",
            "    *   **Causa:** Esta exce√ß√£o ocorrer√° se a lista `valores` for vazia (ou seja, `len(valores)` for 0). A divis√£o por zero n√£o √© permitida em Python e resultar√° neste erro.\n",
            "    *   **Como evitar/tratar:** √â responsabilidade do chamador garantir que a lista de entrada n√£o esteja vazia antes de chamar a fun√ß√£o. Uma verifica√ß√£o condicional (`if valores:`) ou um bloco `try-except` pode ser usado para lidar com este cen√°rio.\n",
            "\n",
            "## 6. Exemplos de Uso\n",
            "\n",
            "### Exemplo 1: Calculando a m√©dia de uma lista de inteiros\n",
            "\n",
            "```python\n",
            "# Lista de n√∫meros inteiros\n",
            "numeros_inteiros = [10, 20, 30, 40, 50]\n",
            "\n",
            "# Chamando a fun√ß√£o\n",
            "media_inteiros = calcular_media(numeros_inteiros)\n",
            "\n",
            "# Imprimindo o resultado\n",
            "print(f\"A m√©dia dos n√∫meros {numeros_inteiros} √©: {media_inteiros}\")\n",
            "# Sa√≠da esperada: A m√©dia dos n√∫meros [10, 20, 30, 40, 50] √©: 30.0\n",
            "```\n",
            "\n",
            "### Exemplo 2: Calculando a m√©dia de uma lista de n√∫meros decimais\n",
            "\n",
            "```python\n",
            "# Lista de notas (n√∫meros decimais)\n",
            "notas = [7.5, 8.0, 6.5, 9.0, 7.0]\n",
            "\n",
            "# Chamando a fun√ß√£o\n",
            "media_notas = calcular_media(notas)\n",
            "\n",
            "# Imprimindo o resultado\n",
            "print(f\"A m√©dia das notas {notas} √©: {media_notas}\")\n",
            "# Sa√≠da esperada: A m√©dia das notas [7.5, 8.0, 6.5, 9.0, 7.0] √©: 7.6\n",
            "```\n",
            "\n",
            "### Exemplo 3: Calculando a m√©dia de uma tupla de n√∫meros\n",
            "\n",
            "```python\n",
            "# Tupla de dados\n",
            "dados_tupla = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
            "\n",
            "# Chamando a fun√ß√£o\n",
            "media_tupla = calcular_media(dados_tupla)\n",
            "\n",
            "# Imprimindo o resultado\n",
            "print(f\"A m√©dia dos dados na tupla {dados_tupla} √©: {media_tupla}\")\n",
            "# Sa√≠da esperada: A m√©dia dos dados na tupla (1, 2, 3, 4, 5, 6, 7, 8, 9, 10) √©: 5.5\n",
            "```\n",
            "\n",
            "### Exemplo 4: Tratamento de erro para lista vazia\n",
            "\n",
            "```python\n",
            "# Lista vazia\n",
            "lista_vazia = []\n",
            "\n",
            "try:\n",
            "    # Tentando calcular a m√©dia de uma lista vazia\n",
            "    media_vazia = calcular_media(lista_vazia)\n",
            "    print(f\"A m√©dia da lista vazia √©: {media_vazia}\")\n",
            "except ZeroDivisionError:\n",
            "    # Capturando e tratando o erro\n",
            "    print(\"Erro: N√£o √© poss√≠vel calcular a m√©dia de uma lista vazia. Por favor, forne√ßa uma lista com pelo menos um elemento.\")\n",
            "# Sa√≠da esperada: Erro: N√£o √© poss√≠vel calcular a m√©dia de uma lista vazia. Por favor, forne√ßa uma lista com pelo menos um elemento.\n",
            "```\n",
            "\n",
            "### Exemplo 5: Calculando a m√©dia com um √∫nico elemento\n",
            "\n",
            "```python\n",
            "# Lista com um √∫nico valor\n",
            "valor_unico = [42]\n",
            "\n",
            "# Chamando a fun√ß√£o\n",
            "media_unica = calcular_media(valor_unico)\n",
            "\n",
            "# Imprimindo o resultado\n",
            "print(f\"A m√©dia do valor √∫nico {valor_unico} √©: {media_unica}\")\n",
            "# Sa√≠da esperada: A m√©dia do valor √∫nico [42] √©: 42.0\n",
            "```\n",
            "\n",
            "## 7. Considera√ß√µes e Boas Pr√°ticas\n",
            "\n",
            "*   **Valida√ß√£o de Entrada:** A fun√ß√£o atual assume que `valores` cont√©m apenas n√∫meros. Para maior robustez em um ambiente de produ√ß√£o, seria prudente adicionar valida√ß√£o interna para verificar se cada elemento do iter√°vel √© realmente num√©rico. Caso contr√°rio, poderia ocorrer um `TypeError` ao tentar somar tipos n√£o num√©ricos.\n",
            "*   **Tratamento de Listas Vazias:** Embora o `ZeroDivisionError` seja captur√°vel, em algumas aplica√ß√µes, pode ser desej√°vel que a fun√ß√£o retorne um valor espec√≠fico (como `0` ou `None`) para uma lista vazia, ou que levante um `ValueError` mais descritivo em vez de um `ZeroDivisionError`.\n",
            "    *   **Exemplo de melhoria com valida√ß√£o e type hinting:**\n",
            "        ```python\n",
            "        from typing import List, Union\n",
            "\n",
            "        def calcular_media_aprimorada(valores: List[Union[int, float]]) -> float:\n",
            "            \"\"\"\n",
            "            Recebe uma lista de n√∫meros e retorna a m√©dia aritm√©tica.\n",
            "            Levanta ValueError se a lista estiver vazia ou contiver n√£o-n√∫meros.\n",
            "            \"\"\"\n",
            "            if not valores:\n",
            "                raise ValueError(\"A lista de valores n√£o pode ser vazia para calcular a m√©dia.\")\n",
            "\n",
            "            for valor in valores:\n",
            "                if not isinstance(valor, (int, float)):\n",
            "                    raise TypeError(f\"Todos os elementos devem ser n√∫meros (int ou float). Encontrado: {type(valor).__name__}\")\n",
            "\n",
            "            return sum(valores) / len(valores)\n",
            "        ```\n",
            "*   **Desempenho:** Para listas de tamanho moderado, o uso das fun√ß√µes built-in `sum()` e `len()` √© altamente otimizado e eficiente. Para listas extremamente grandes, a performance ser√° proporcional ao n√∫mero de elementos, mas ainda assim muito boa devido √† implementa√ß√£o em C dessas fun√ß√µes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Claro! Abaixo est√° a documenta√ß√£o t√©cnica detalhada para a fun√ß√£o `calcular_media`, incluindo exemplos de uso.\n",
        "\n",
        "---\n",
        "\n",
        "# Documenta√ß√£o T√©cnica da Fun√ß√£o `calcular_media`\n",
        "\n",
        "## 1. Vis√£o Geral\n",
        "\n",
        "A fun√ß√£o `calcular_media` √© uma utilidade simples e direta projetada para calcular a m√©dia aritm√©tica de uma cole√ß√£o de n√∫meros. Ela recebe uma lista (ou qualquer iter√°vel) de valores num√©ricos e retorna a soma desses valores dividida pela quantidade de elementos. √â ideal para cen√°rios onde √© necess√°rio obter um valor central representativo de um conjunto de dados.\n",
        "\n",
        "## 2. Assinatura da Fun√ß√£o\n",
        "\n",
        "```python\n",
        "def calcular_media(valores):\n",
        "```\n",
        "\n",
        "## 3. Par√¢metros\n",
        "\n",
        "*   **`valores`** (obrigat√≥rio)\n",
        "    *   **Tipo:** `list` (ou qualquer iter√°vel, como `tuple`, `set`, etc.)\n",
        "    *   **Descri√ß√£o:** Uma cole√ß√£o de n√∫meros (inteiros ou decimais) dos quais a m√©dia ser√° calculada.\n",
        "    *   **Restri√ß√µes:**\n",
        "        *   Todos os elementos dentro do iter√°vel devem ser do tipo num√©rico (`int` ou `float`).\n",
        "        *   **N√£o deve ser uma lista vazia.** Se uma lista vazia for fornecida, a fun√ß√£o levantar√° uma exce√ß√£o `ZeroDivisionError`.\n",
        "\n",
        "## 4. Retorno\n",
        "\n",
        "*   **Tipo:** `float`\n",
        "*   **Descri√ß√£o:** A m√©dia aritm√©tica dos n√∫meros fornecidos. O resultado √© sempre um n√∫mero de ponto flutuante, mesmo que todos os valores de entrada sejam inteiros (devido √† opera√ß√£o de divis√£o).\n",
        "\n",
        "## 5. Exce√ß√µes / Erros Potenciais\n",
        "\n",
        "*   **`ZeroDivisionError`**\n",
        "    *   **Causa:** Esta exce√ß√£o ocorrer√° se a lista `valores` for vazia (ou seja, `len(valores)` for 0). A divis√£o por zero n√£o √© permitida em Python e resultar√° neste erro.\n",
        "    *   **Como evitar/tratar:** √â responsabilidade do chamador garantir que a lista de entrada n√£o esteja vazia antes de chamar a fun√ß√£o. Uma verifica√ß√£o condicional (`if valores:`) ou um bloco `try-except` pode ser usado para lidar com este cen√°rio.\n",
        "\n",
        "## 6. Exemplos de Uso\n",
        "\n",
        "### Exemplo 1: Calculando a m√©dia de uma lista de inteiros\n",
        "\n",
        "```python\n",
        "# Lista de n√∫meros inteiros\n",
        "numeros_inteiros = [10, 20, 30, 40, 50]\n",
        "\n",
        "# Chamando a fun√ß√£o\n",
        "media_inteiros = calcular_media(numeros_inteiros)\n",
        "\n",
        "# Imprimindo o resultado\n",
        "print(f\"A m√©dia dos n√∫meros {numeros_inteiros} √©: {media_inteiros}\")\n",
        "# Sa√≠da esperada: A m√©dia dos n√∫meros [10, 20, 30, 40, 50] √©: 30.0\n",
        "```\n",
        "\n",
        "### Exemplo 2: Calculando a m√©dia de uma lista de n√∫meros decimais\n",
        "\n",
        "```python\n",
        "# Lista de notas (n√∫meros decimais)\n",
        "notas = [7.5, 8.0, 6.5, 9.0, 7.0]\n",
        "\n",
        "# Chamando a fun√ß√£o\n",
        "media_notas = calcular_media(notas)\n",
        "\n",
        "# Imprimindo o resultado\n",
        "print(f\"A m√©dia das notas {notas} √©: {media_notas}\")\n",
        "# Sa√≠da esperada: A m√©dia das notas [7.5, 8.0, 6.5, 9.0, 7.0] √©: 7.6\n",
        "```\n",
        "\n",
        "### Exemplo 3: Calculando a m√©dia de uma tupla de n√∫meros\n",
        "\n",
        "```python\n",
        "# Tupla de dados\n",
        "dados_tupla = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
        "\n",
        "# Chamando a fun√ß√£o\n",
        "media_tupla = calcular_media(dados_tupla)\n",
        "\n",
        "# Imprimindo o resultado\n",
        "print(f\"A m√©dia dos dados na tupla {dados_tupla} √©: {media_tupla}\")\n",
        "# Sa√≠da esperada: A m√©dia dos dados na tupla (1, 2, 3, 4, 5, 6, 7, 8, 9, 10) √©: 5.5\n",
        "```\n",
        "\n",
        "### Exemplo 4: Tratamento de erro para lista vazia\n",
        "\n",
        "```python\n",
        "# Lista vazia\n",
        "lista_vazia = []\n",
        "\n",
        "try:\n",
        "    # Tentando calcular a m√©dia de uma lista vazia\n",
        "    media_vazia = calcular_media(lista_vazia)\n",
        "    print(f\"A m√©dia da lista vazia √©: {media_vazia}\")\n",
        "except ZeroDivisionError:\n",
        "    # Capturando e tratando o erro\n",
        "    print(\"Erro: N√£o √© poss√≠vel calcular a m√©dia de uma lista vazia. Por favor, forne√ßa uma lista com pelo menos um elemento.\")\n",
        "# Sa√≠da esperada: Erro: N√£o √© poss√≠vel calcular a m√©dia de uma lista vazia. Por favor, forne√ßa uma lista com pelo menos um elemento.\n",
        "```\n",
        "\n",
        "### Exemplo 5: Calculando a m√©dia com um √∫nico elemento\n",
        "\n",
        "```python\n",
        "# Lista com um √∫nico valor\n",
        "valor_unico = [42]\n",
        "\n",
        "# Chamando a fun√ß√£o\n",
        "media_unica = calcular_media(valor_unico)\n",
        "\n",
        "# Imprimindo o resultado\n",
        "print(f\"A m√©dia do valor √∫nico {valor_unico} √©: {media_unica}\")\n",
        "# Sa√≠da esperada: A m√©dia do valor √∫nico [42] √©: 42.0\n",
        "```\n",
        "\n",
        "## 7. Considera√ß√µes e Boas Pr√°ticas\n",
        "\n",
        "*   **Valida√ß√£o de Entrada:** A fun√ß√£o atual assume que `valores` cont√©m apenas n√∫meros. Para maior robustez em um ambiente de produ√ß√£o, seria prudente adicionar valida√ß√£o interna para verificar se cada elemento do iter√°vel √© realmente num√©rico. Caso contr√°rio, poderia ocorrer um `TypeError` ao tentar somar tipos n√£o num√©ricos.\n",
        "*   **Tratamento de Listas Vazias:** Embora o `ZeroDivisionError` seja captur√°vel, em algumas aplica√ß√µes, pode ser desej√°vel que a fun√ß√£o retorne um valor espec√≠fico (como `0` ou `None`) para uma lista vazia, ou que levante um `ValueError` mais descritivo em vez de um `ZeroDivisionError`.\n",
        "    *   **Exemplo de melhoria com valida√ß√£o e type hinting:**\n",
        "        ```python\n",
        "        from typing import List, Union\n",
        "\n",
        "        def calcular_media_aprimorada(valores: List[Union[int, float]]) -> float:\n",
        "            \"\"\"\n",
        "            Recebe uma lista de n√∫meros e retorna a m√©dia aritm√©tica.\n",
        "            Levanta ValueError se a lista estiver vazia ou contiver n√£o-n√∫meros.\n",
        "            \"\"\"\n",
        "            if not valores:\n",
        "                raise ValueError(\"A lista de valores n√£o pode ser vazia para calcular a m√©dia.\")\n",
        "\n",
        "            for valor in valores:\n",
        "                if not isinstance(valor, (int, float)):\n",
        "                    raise TypeError(f\"Todos os elementos devem ser n√∫meros (int ou float). Encontrado: {type(valor).__name__}\")\n",
        "\n",
        "            return sum(valores) / len(valores)\n",
        "        ```\n",
        "*   **Desempenho:** Para listas de tamanho moderado, o uso das fun√ß√µes built-in `sum()` e `len()` √© altamente otimizado e eficiente. Para listas extremamente grandes, a performance ser√° proporcional ao n√∫mero de elementos, mas ainda assim muito boa devido √† implementa√ß√£o em C dessas fun√ß√µes."
      ],
      "metadata": {
        "id": "GpAh2EVMznR5"
      }
    }
  ]
}